{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "all_paths = []\n",
    "for root, dirs, files in os.walk(\"./processed_data\"):\n",
    "    for file in files:\n",
    "        if file.endswith(\".txt\"):\n",
    "             all_paths.append(os.path.join(root, file))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tokenizer\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "context_length = 512\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./new_tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [5645, 299, 276, 8633, 221, 173, 254, 247, 224, 10067], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('Hva√∞ er a√∞ fr√©tta üòÅ ?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3417cd4a1228434caee099111f2cc99b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/636442 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22a97e79c0774ab5b3ef14aa8629e06a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/159111 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "portion = 1\n",
    "all_paths = all_paths[:int(len(all_paths) * portion)]\n",
    "\n",
    "train_paths = all_paths[:int(len(all_paths) * 0.8)]\n",
    "test_paths = all_paths[int(len(all_paths) * 0.8):]\n",
    "\n",
    "dataset = load_dataset('text', data_files={\"train\": train_paths, \"test\":test_paths}).with_format(\"torch\")\n",
    "\n",
    "train_dataset = dataset['train']\n",
    "test_dataset = dataset['test']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "\n",
    "context_length = 512\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    # sequence length is the same as the context length\n",
    "    examples = tokenizer(examples[\"text\"])\n",
    "    concatenated_examples = {k: list(chain(*examples[k])) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    if total_length >= context_length:\n",
    "        total_length = (total_length // context_length) * context_length\n",
    "\n",
    "    result = {\n",
    "        k: [t[i : i + context_length] for i in range(0, total_length, context_length)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "tokanized_train_dataset = train_dataset.map(tokenize_function, batched=True, batch_size=1000, remove_columns=[\"text\"])\n",
    "tokanized_test_dataset = test_dataset.map(tokenize_function, batched=True, batch_size=1000, remove_columns=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b89a80c332be47c48fff1a12206ef92c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/2 shards):   0%|          | 0/373884 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a22d0c1760c145379daa2658d8231639",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/93512 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# save the tokenized datasets\n",
    "tokanized_train_dataset.save_to_disk(\"tokanized_train_dataset\")\n",
    "tokanized_test_dataset.save_to_disk(\"tokanized_test_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "# load from disk\n",
    "tokanized_train_dataset = load_from_disk(\"tokanized_train_dataset\")\n",
    "tokanized_test_dataset = load_from_disk(\"tokanized_test_dataset\")\n",
    "\n",
    "# shuffle the datasets\n",
    "tokanized_train_dataset = tokanized_train_dataset.shuffle()\n",
    "tokanized_test_dataset = tokanized_test_dataset.shuffle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['input_ids', 'attention_mask'],\n",
       "     num_rows: 373884\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['input_ids', 'attention_mask'],\n",
       "     num_rows: 93512\n",
       " }))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokanized_train_dataset, tokanized_test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokanized_train_dataset[100][\"input_ids\"].shape == tokanized_train_dataset[100][\n",
    "    \"attention_mask\"\n",
    "].shape == (context_length,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Config, GPT2LMHeadModel\n",
    "\n",
    "scale = 1\n",
    "\n",
    "# Initializing a GPT2 configuration\n",
    "configuration = GPT2Config(\n",
    "    vocab_size=len(tokenizer),\n",
    "    n_ctx=context_length,\n",
    "    bos_token_id=tokenizer.bos_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    n_embd=int(768 * scale),\n",
    "    n_layer=int(12 * scale),\n",
    "    n_head=int(12 * scale),\n",
    "        \n",
    ")\n",
    "\n",
    "# Initializing a model from the configuration\n",
    "model = GPT2LMHeadModel(configuration)\n",
    "\n",
    "# Accessing the model configuration\n",
    "configuration = model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2Config {\n",
       "  \"activation_function\": \"gelu_new\",\n",
       "  \"attn_pdrop\": 0.1,\n",
       "  \"bos_token_id\": 0,\n",
       "  \"embd_pdrop\": 0.1,\n",
       "  \"eos_token_id\": 0,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"layer_norm_epsilon\": 1e-05,\n",
       "  \"model_type\": \"gpt2\",\n",
       "  \"n_ctx\": 512,\n",
       "  \"n_embd\": 768,\n",
       "  \"n_head\": 12,\n",
       "  \"n_inner\": null,\n",
       "  \"n_layer\": 12,\n",
       "  \"n_positions\": 1024,\n",
       "  \"reorder_and_upcast_attn\": false,\n",
       "  \"resid_pdrop\": 0.1,\n",
       "  \"scale_attn_by_inverse_layer_idx\": false,\n",
       "  \"scale_attn_weights\": true,\n",
       "  \"summary_activation\": null,\n",
       "  \"summary_first_dropout\": 0.1,\n",
       "  \"summary_proj_to_labels\": true,\n",
       "  \"summary_type\": \"cls_index\",\n",
       "  \"summary_use_proj\": true,\n",
       "  \"transformers_version\": \"4.37.0.dev0\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 32000\n",
       "}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ICE GPT-2 size: 110.4M parameters\n"
     ]
    }
   ],
   "source": [
    "model_size = sum(t.numel() for t in model.parameters())\n",
    "print(f\"ICE GPT-2 size: {model_size/1000**2:.1f}M parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, mlm=False, pad_to_multiple_of=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Mar 12 18:07:58 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.65.01    Driver Version: 516.94       CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:01:00.0  On |                  N/A |\n",
      "|  0%   37C    P8    15W / 250W |   1095MiB /  8192MiB |      5%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A        66      G   /Xwayland                       N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msigurdurhaukur\u001b[0m (\u001b[33msigurdurhaukur-team\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/haukur/tokanicer/wandb/run-20240312_180859-jb32vzbv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sigurdurhaukur-team/huggingface/runs/jb32vzbv' target=\"_blank\">frosty-universe-54</a></strong> to <a href='https://wandb.ai/sigurdurhaukur-team/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sigurdurhaukur-team/huggingface' target=\"_blank\">https://wandb.ai/sigurdurhaukur-team/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sigurdurhaukur-team/huggingface/runs/jb32vzbv' target=\"_blank\">https://wandb.ai/sigurdurhaukur-team/huggingface/runs/jb32vzbv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='921' max='11683' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  921/11683 4:16:56 < 387:17:37, 0.01 it/s, Epoch 0.08/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>5.568800</td>\n",
       "      <td>5.495662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>5.538700</td>\n",
       "      <td>5.482532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>5.538700</td>\n",
       "      <td>5.470903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>5.518000</td>\n",
       "      <td>5.466811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>5.518000</td>\n",
       "      <td>5.439738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>5.486500</td>\n",
       "      <td>5.425218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>5.486500</td>\n",
       "      <td>5.415768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>5.445100</td>\n",
       "      <td>5.391989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>5.445100</td>\n",
       "      <td>5.383941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>5.418500</td>\n",
       "      <td>5.382714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>5.418500</td>\n",
       "      <td>5.357174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10424' max='23378' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10424/23378 10:23 < 12:55, 16.70 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 38\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# import os\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\u001b[39;00m\n\u001b[1;32m     30\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     31\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     32\u001b[0m     args\u001b[38;5;241m=\u001b[39margs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     35\u001b[0m     data_collator\u001b[38;5;241m=\u001b[39mdata_collator,\n\u001b[1;32m     36\u001b[0m     optimizers\u001b[38;5;241m=\u001b[39m(optimizer, \u001b[38;5;28;01mNone\u001b[39;00m),)\n\u001b[0;32m---> 38\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/transformers/trainer.py:1543\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1541\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1542\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1543\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1544\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1545\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1546\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1547\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1548\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/transformers/trainer.py:1920\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;241m=\u001b[39m epoch \u001b[38;5;241m+\u001b[39m (step \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m steps_skipped) \u001b[38;5;241m/\u001b[39m steps_in_epoch\n\u001b[1;32m   1918\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m-> 1920\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1922\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_substep_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/transformers/trainer.py:2264\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2262\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2263\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_evaluate:\n\u001b[0;32m-> 2264\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2265\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_report_to_hp_search(trial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step, metrics)\n\u001b[1;32m   2267\u001b[0m     \u001b[38;5;66;03m# Run delayed LR scheduler now that metrics are populated\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/transformers/trainer.py:3052\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3049\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   3051\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 3052\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3053\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3054\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvaluation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3055\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[1;32m   3056\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[1;32m   3057\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   3058\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3059\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3060\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3062\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[1;32m   3063\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/transformers/trainer.py:3241\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3238\u001b[0m         batch_size \u001b[38;5;241m=\u001b[39m observed_batch_size\n\u001b[1;32m   3240\u001b[0m \u001b[38;5;66;03m# Prediction step\u001b[39;00m\n\u001b[0;32m-> 3241\u001b[0m loss, logits, labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprediction_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3242\u001b[0m main_input_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmain_input_name\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3243\u001b[0m inputs_decode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_input(inputs[main_input_name]) \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39minclude_inputs_for_metrics \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/transformers/trainer.py:3458\u001b[0m, in \u001b[0;36mTrainer.prediction_step\u001b[0;34m(self, model, inputs, prediction_loss_only, ignore_keys)\u001b[0m\n\u001b[1;32m   3456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_labels \u001b[38;5;129;01mor\u001b[39;00m loss_without_labels:\n\u001b[1;32m   3457\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 3458\u001b[0m         loss, outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   3459\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m   3461\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mdict\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/transformers/trainer.py:2760\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2758\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2759\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2760\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2761\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   2762\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   2763\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/accelerate/utils/operations.py:680\u001b[0m, in \u001b[0;36mconvert_outputs_to_fp32.<locals>.forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 680\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/accelerate/utils/operations.py:668\u001b[0m, in \u001b[0;36mConvertOutputsToFp32.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 668\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m convert_to_fp32(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/amp/autocast_mode.py:16\u001b[0m, in \u001b[0;36mautocast_decorator.<locals>.decorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_autocast\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m autocast_instance:\n\u001b[0;32m---> 16\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/transformers/models/gpt2/modeling_gpt2.py:1074\u001b[0m, in \u001b[0;36mGPT2LMHeadModel.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1066\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1067\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1068\u001b[0m \u001b[38;5;124;03m    Labels for language modeling. Note that the labels **are shifted** inside the model, i.e. you can set\u001b[39;00m\n\u001b[1;32m   1069\u001b[0m \u001b[38;5;124;03m    `labels = input_ids` Indices are selected in `[-100, 0, ..., config.vocab_size]` All labels set to `-100`\u001b[39;00m\n\u001b[1;32m   1070\u001b[0m \u001b[38;5;124;03m    are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n\u001b[1;32m   1071\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1072\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1074\u001b[0m transformer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1075\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1076\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1077\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1078\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1079\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1080\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1081\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1082\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1083\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1084\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1085\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1086\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1087\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1088\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1089\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m transformer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;66;03m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/transformers/models/gpt2/modeling_gpt2.py:888\u001b[0m, in \u001b[0;36mGPT2Model.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    876\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    877\u001b[0m         block\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    878\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    885\u001b[0m         output_attentions,\n\u001b[1;32m    886\u001b[0m     )\n\u001b[1;32m    887\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 888\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_past\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_past\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    896\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    897\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    899\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/transformers/models/gpt2/modeling_gpt2.py:427\u001b[0m, in \u001b[0;36mGPT2Block.forward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    425\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m    426\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_2(hidden_states)\n\u001b[0;32m--> 427\u001b[0m feed_forward_hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;66;03m# residual connection\u001b[39;00m\n\u001b[1;32m    429\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m feed_forward_hidden_states\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/transformers/models/gpt2/modeling_gpt2.py:355\u001b[0m, in \u001b[0;36mGPT2MLP.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: Optional[Tuple[torch\u001b[38;5;241m.\u001b[39mFloatTensor]]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor:\n\u001b[1;32m    354\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mc_fc(hidden_states)\n\u001b[0;32m--> 355\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mact\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    356\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mc_proj(hidden_states)\n\u001b[1;32m    357\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(hidden_states)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/transformers/activations.py:56\u001b[0m, in \u001b[0;36mNewGELUActivation.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m+\u001b[39m torch\u001b[38;5;241m.\u001b[39mtanh(math\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;241m2.0\u001b[39m \u001b[38;5;241m/\u001b[39m math\u001b[38;5;241m.\u001b[39mpi) \u001b[38;5;241m*\u001b[39m (\u001b[38;5;28minput\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.044715\u001b[39m \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mpow(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m3.0\u001b[39m))))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AdamW\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-4, weight_decay=0.1)\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"icebreaker\",\n",
    "    overwrite_output_dir=True,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    # eval_steps=5_000,\n",
    "    eval_steps=10,\n",
    "    logging_steps=20,\n",
    "    gradient_accumulation_steps=8,\n",
    "    num_train_epochs=1,\n",
    "    # warmup_steps=1_000,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    learning_rate=5e-4,\n",
    "    save_steps=100,\n",
    "    save_total_limit=2,\n",
    "    fp16=True,\n",
    ")\n",
    "\n",
    "# import os\n",
    "# os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokanized_train_dataset,\n",
    "    eval_dataset=tokanized_test_dataset,\n",
    "    data_collator=data_collator,\n",
    "    optimizers=(optimizer, None),)\n",
    "\n",
    "trainer.train(resume_from_checkpoint=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('icebreaker/tokenizer_config.json',\n",
       " 'icebreaker/special_tokens_map.json',\n",
       " 'icebreaker/vocab.json',\n",
       " 'icebreaker/merges.txt',\n",
       " 'icebreaker/added_tokens.json',\n",
       " 'icebreaker/tokenizer.json')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"icebreaker\")\n",
    "tokenizer.save_pretrained(\"icebreaker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Fr√©ttir> √ç g√¶rkv√∂ldiar√°√∞, afhenti forseta Al√æingis, √Åstu Ragnhei√∞i J√≥hannesd√≥ttur, frumvarp a√∞ n√Ωrri stj√≥rnarskr√° √≠ I√∞n√≥ √≠ dag. Frumvarpi√∞ var sam√æykkt einr√≥ma me√∞ atkv√¶√∞um allra r√°√∞sfulltr√∫a √° s√≠√∞asta fundi r√°√∞sins, mi√∞vikudaginn 27. j√∫l√≠ s√≠√∞astli√∞inn. √ç frumvarpinu er gert r√°√∞ fyrir a√∞ breytingar √° stj√≥rnarskr√° s√©u framvegis bornar undir atkv√¶√∞i allra kosningab√¶rra manna √≠ landinu til sam√æykktar e√∞a synjunar. Fulltr√∫ar √≠ Stj√≥rnlagar√°√∞i eru einhuga um a√∞ veita beri landsm√∂nnum f√¶ri √° a√∞ grei√∞a atkv√¶√∞i um n√Ωja stj√≥rnarskr√° √°√∞ur en Al√æingi afgrei√∞ir frumvarpi√∞ endanlega. Komi fram hugmyndir um breytingar √° frumvarpi Stj√≥rnlagar√°√∞s l√Ωsa fulltr√∫ar √≠ r√°√∞inu sig rei√∞ub√∫na til a√∞ koma aftur a√∞ m√°linu √°√∞ur en √æj√≥√∞aratkv√¶√∞agrei√∞sla fer fram. Frumvarpi√∞ hefst √° a√∞faraor√∞um og telur alls 114 √°kv√¶√∞i √≠ n√≠u k√∂flum. A√∞faraor√∞ frumvarpsins hefjast √° eftirfarandi or√∞um: ‚ÄûVi√∞ sem byggjum √çsland viljum skapa r√©ttl√°tt samf√©lag √æar sem allir sitja vi√∞ sama bor√∞. √ìl√≠kur uppruni okkar au√∞gar heildina og saman berum vi√∞ √°byrg√∞ √° arfi kynsl√≥√∞anna, landi og s√∂gu, n√°tt√∫ru, tungu og menningu.\"Lei√∞arstefin sem Stj√≥rnlagar√°√∞ hefur haft √≠ st√∂rfum s√≠num eru einkum √ærj√∫: Valddreifing,gegns√¶i og √°byrg√∞. Leitast hefur veri√∞ vi√∞ a√∞ auka valddreifingu me√∞ sk√Ωraria√∞greiningu valdhafanna √æriggja. Auk √æess er kve√∞i√∞ √° um aukna √æ√°ttt√∂ku almenningsa√∞ √°kv√∂r√∞unum sem mun einnig lei√∞a til aukinnar valddreifingar. R√°√∞i√∞ lag√∞i jafnframtmikla √°herslu √° sk√Ωra og skiljanlega framsetningu stj√≥rnarskr√°rinnar, b√¶√∞i hva√∞ var√∞arm√°lfar og heildaruppbyggingu, en ekki s√≠√∞ur a√∞ sk√Ωrt v√¶ri hver hef√∞i vald og b√¶ri √æar aflei√∞andi √°byrg√∞ √≠ stj√≥rnskipaninni.Mannr√©ttindakaflinn hefur veri√∞ endurn√Ωja√∞ur og heitir n√∫ Mannr√©ttindi og n√°tt√∫ra.Jafnr√¶√∞isreglan er √≠tarlegri en √≠ n√∫gildandi stj√≥rnarskr√° og s√©rstaklega er kve√∞i√∞ √° uma√∞ √∂llum skuli trygg√∞ur r√©ttur til a√∞ lifa me√∞ reisn. Kve√∞i√∞ er √° um a√∞ √∂llum b√∂rnumskuli trygg√∞ √≠ l√∂gum s√∫ vernd og um√∂nnun sem velfer√∞ √æeirra krefjist. Me√∞ √°herslu√° auki√∞ gegns√¶i og uppl√Ωsingaskyldu opinberra a√∞ila er leitast vi√∞ a√∞ tryggja munbetur r√©tt borgaranna gagnvart stj√≥rnv√∂ldum. R√©ttur fj√∂lmi√∞la er settur √≠ stj√≥rnarskr√° oguppl√Ωsingafrelsi er auki√∞ en s√©rstaklega er kve√∞i√∞ √° um a√∞ √∂llum s√© frj√°lst a√∞ safna ogmi√∞la uppl√Ωsingum og a√∞ stj√≥rns√Ωsla skuli vera gegns√¶.Me√∞al fleiri n√Ωm√¶la √≠ kaflanum um Mannr√©ttindi og n√°tt√∫ru eru √°kv√¶√∞in um n√°tt√∫ru√çslands og umhverfi og au√∞linda√°kv√¶√∞i, √æar sem kemur fram a√∞ au√∞lindir sem ekki eru√≠ einkaeigu s√©u sameiginleg og √¶varandi eign √æj√≥√∞arinnar. √û√° kemur fram n√Ωtt √°kv√¶√∞ium a√∞ stj√≥rnv√∂ldum beri a√∞ uppl√Ωsa almenning um √°stand umhverfis og n√°tt√∫ru og √°hrifframkv√¶mda √æar √°.Vi√∞ endursko√∞un √° stj√≥rnskipaninni var √°hersla l√∂g√∞ √° a√∞ dreifa valdi og auka √°a√∞greiningu l√∂ggjafarvalds og framkv√¶mdarvalds. Margar breytingar eru ger√∞ar semhafa √≠ f√∂r me√∞ s√©r b√¶tt l√∂ggjafarstarf √æingsins. S√©rst√∂k √°hersla var l√∂g√∞ √° a√∞ eflaeftirlits- og fj√°rstj√≥rnarhlutverk √æingsins og fj√∂lm√∂rg n√Ωm√¶li m√° finna √≠ kafla um Al√æingisem hafa √æa√∞ markmi√∞ a√∞ lei√∞arlj√≥si. √û√° er talsvert um √°kv√¶√∞i er kalla √° sam√æykktaukins meirihluta √æingmanna, svo sem kosning forseta Al√æingis, sem √¶tlun er a√∞ aukisamr√°√∞ milli meiri- og minnihluta √æingmanna. N√Ω stofnun, L√∂gr√©tta, sem hefur √æa√∞hlutverk a√∞ sko√∞a hvort l√∂g standist stj√≥rnarskr√° er sett √° f√≥t.√ùmis n√Ωm√¶li eru √≠ frumvarpinu sem tryggja r√©tt almennings til l√Ω√∞r√¶√∞islegrar √æ√°ttt√∂kua√∞ √°kv√∂r√∞unum, en samkv√¶mt frumvarpinu geta t√≠u af hundra√∞i kj√≥senda krafist√æj√≥√∞aratkv√¶√∞is um l√∂g sem Al√æingi hefur sam√æykkt og tveir af hundra√∞i kj√≥senda getalagt fram √æingm√°l √° Al√æingi. Me√∞ √æessum breytingum mun √çsland vera me√∞al √æeirra√æj√≥√∞a sem tryggir sem best r√©tt almennings til √æ√°ttt√∂ku √≠ opinberum √°kv√∂r√∞unum, e√∞abeint l√Ω√∞r√¶√∞i.Kosningarerfi√∞ er teki√∞ til heildarendursko√∞unar. Fram kemur a√∞ atkv√¶√∞i kj√≥sendaalls sta√∞ar √° landinu vegi jafnt. Kve√∞i√∞ er √° um a√∞ kj√≥sandi geti me√∞ pers√≥nukj√∂rivali√∞ frambj√≥√∞endur √ævert √° lista en heimilt s√© a√∞ m√¶la fyrir um √≠ l√∂gum a√∞ vali√∞ s√©einskor√∞a√∞ vi√∞ kj√∂rd√¶mislista e√∞a landslista s√∂mu samtaka. Kj√∂rd√¶mi skuli vera eitt til√°tta.Forseti skal ekki sitja lengur en √ærj√∫ kj√∂rt√≠mabil samkv√¶mt frumvarpinu og enginnr√°√∞herra getur gegnt sama emb√¶ttinu lengur en √≠ √°tta √°r. √û√° k√Ωs Al√æingi s√©rfors√¶tisr√°√∞herra me√∞ beinni kosningu √≠ kj√∂lfar √æingkosninga en me√∞ √æv√≠ tekur √æingr√¶√∞i√∞√° sig beina mynd. √û√° er n√Ωm√¶li f√≥lgi√∞ √≠ √æv√≠ a√∞ me√∞ vantrauststill√∂gu √° fors√¶tisr√°√∞herra√æurfi a√∞ fylgja tillaga um eftirmann hans. S√© al√æingisma√∞ur skipa√∞ur r√°√∞herra v√≠kur hann√∫r √æings√¶ti √° me√∞an hann gegnir emb√¶ttinu og varama√∞ur tekur s√¶ti hans. √Åkv√¶√∞ium r√°√∞herra og r√≠kisstj√≥rn eru mun √≠tarlegri en √≠ n√∫verandi stj√≥rnskipun og kve√∞i√∞ er√° um a√∞ r√≠kisstj√≥rn s√© fj√∂lskipa√∞ stj√≥rnvald og taki √°kv√∂r√∞un sem sl√≠k √≠ mikilv√¶gumog stefnumarkandi m√°lum. √û√° er kve√∞i√∞ √° um uppl√Ωsinga- og sannleiksskyldur√°√∞herra gagnvart √æinginu og tryggt a√∞ h√¶fni og m√°lefnaleg sj√≥narmi√∞ skuli r√°√∞a vi√∞emb√¶ttisveitingar.N√Ωr kafli um d√≥mst√≥la er lag√∞ur fram en H√¶stir√©ttur √çslands er skilgreindur √¶√∞stid√≥mst√≥ll r√≠kisins. N√°nar er kve√∞i√∞ √° um l√∂gs√∂gu d√≥mst√≥la, skipan d√≥mara og sj√°lfst√¶√∞i√æeirra √≠ frumvarpinu.√Åhersla er l√∂g√∞ √° aukna sj√°lfstj√≥rn sveitarf√©laga.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TextGenerationPipeline\n",
    "\n",
    "# Load the trained model\n",
    "model_path = \"icebreaker\"\n",
    "model = GPT2LMHeadModel.from_pretrained(model_path)\n",
    "model.eval()\n",
    "\n",
    "# Create a text generation pipeline\n",
    "pipeline = TextGenerationPipeline(model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Generate text\n",
    "generated_text = pipeline(\"<Fr√©ttir> √ç g√¶rkv√∂ldi\", max_length=1000, num_return_sequences=1, do_sample=True, top_k=50, top_p=0.8, temperature=1.0)\n",
    "\n",
    "# Print the generated text\n",
    "print(generated_text[0]['generated_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAHHCAYAAABXx+fLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABm/UlEQVR4nO3deVwU9f8H8NfuAstyLfelyKmCeIZKaqYmikdm5p159bXyqsy0tH6aR2WWmYWlmaVWnpVXaSqSt6glnkmeHB4ggtwgx+78/lgZXVmQe4B9PR+PebD72c/Mvofd4uVnPjMjEwRBABEREZERkUtdABEREVFNYwAiIiIio8MAREREREaHAYiIiIiMDgMQERERGR0GICIiIjI6DEBERERkdBiAiIiIyOgwABEREZHRYQAiqgXGjBkDLy+vCq07Z84cyGSyqi2olomNjYVMJsPq1aulLqVEXl5eGDNmjCTvXRd+P0S1DQMQUSlkMlmZlv3790tdKgHYv39/qZ/Thg0bpC6xUtatW4clS5ZIXYaeMWPGwMrKSuoyiMrNROoCiGqzn376Se/5jz/+iPDw8GLtAQEBlXqf7777DlqttkLr/t///R9mzJhRqfevb9544w20a9euWHuHDh0kqKbqrFu3DufPn8eUKVP02j09PZGbmwtTU1NpCiOqgxiAiErx0ksv6T0/duwYwsPDi7U/KicnBxYWFmV+n8r84TIxMYGJCf9Tfljnzp0xaNAgqcuoMTKZDObm5lKXQVSn8BAYUSV17doVzZs3x8mTJ/H000/DwsIC7733HgBg27Zt6Nu3L9zd3aFUKuHr64v58+dDo9HobePROUBFczoWLVqEFStWwNfXF0qlEu3atcPff/+tt66hOUAymQyTJ0/G1q1b0bx5cyiVSgQGBmLXrl3F6t+/fz/atm0Lc3Nz+Pr64ttvvy3zvKJDhw5h8ODBaNSoEZRKJTw8PPDWW28hNze32P5ZWVnh5s2beP7552FlZQUnJydMmzat2O8iLS0NY8aMgVqthq2tLUaPHo20tLTH1lIezZs3R7du3Yq1a7VaNGjQQC88LVq0CB07doSDgwNUKhWCgoLw66+/PvY9Svodrl69GjKZDLGxsWJbWb4nXbt2xY4dOxAXFyce0iv6zpQ0B+ivv/5C586dYWlpCVtbW/Tv3x/R0dEG67xy5QrGjBkDW1tbqNVqjB07Fjk5OY/dz7L65ZdfEBQUBJVKBUdHR7z00ku4efOmXp/ExESMHTsWDRs2hFKphJubG/r376/3u/rnn38QGhoKR0dHqFQqeHt74+WXX66yOsl48J+NRFUgJSUFvXv3xrBhw/DSSy/BxcUFgO6PnZWVFaZOnQorKyv89ddfmD17NjIyMvDZZ589drvr1q1DZmYmXnvtNchkMnz66ad44YUXcO3atceOGh0+fBibN2/GxIkTYW1tja+++goDBw5EfHw8HBwcAACnTp1Cr1694Obmhrlz50Kj0WDevHlwcnIq037/8ssvyMnJwYQJE+Dg4IATJ04gLCwMN27cwC+//KLXV6PRIDQ0FMHBwVi0aBH27t2Lzz//HL6+vpgwYQIAQBAE9O/fH4cPH8b48eMREBCALVu2YPTo0WWqp0hmZiaSk5OLtTs4OEAmk2Ho0KGYM2cOEhMT4erqqvc7u3XrFoYNGya2ffnll3juuecwYsQI5OfnY8OGDRg8eDD++OMP9O3bt1x1laQs35P3338f6enpuHHjBr744gsAKHXuzd69e9G7d2/4+Phgzpw5yM3NRVhYGDp16oSoqKhik+6HDBkCb29vLFiwAFFRUVi5ciWcnZ2xcOHCKtm/sWPHol27dliwYAFu376NL7/8EkeOHMGpU6dga2sLABg4cCD+/fdfvP766/Dy8kJSUhLCw8MRHx8vPu/ZsyecnJwwY8YM2NraIjY2Fps3b650jWSEBCIqs0mTJgmP/mfTpUsXAYCwfPnyYv1zcnKKtb322muChYWFcO/ePbFt9OjRgqenp/g8JiZGACA4ODgId+/eFdu3bdsmABB+//13se2DDz4oVhMAwczMTLhy5YrYdubMGQGAEBYWJrb169dPsLCwEG7evCm2Xb58WTAxMSm2TUMM7d+CBQsEmUwmxMXF6e0fAGHevHl6fdu0aSMEBQWJz7du3SoAED799FOxrbCwUOjcubMAQFi1alWp9ezbt08AUOKSkJAgCIIgXLx4sdjvQhAEYeLEiYKVlZXefj26j/n5+ULz5s2FZ555Rq/d09NTGD16tPjc0OciCIKwatUqAYAQExNT4nsIguHvSd++ffW+J0WKvi8P/35at24tODs7CykpKWLbmTNnBLlcLowaNapYnS+//LLeNgcMGCA4ODgUe69HjR49WrC0tCzx9fz8fMHZ2Vlo3ry5kJubK7b/8ccfAgBh9uzZgiAIQmpqqgBA+Oyzz0rc1pYtWwQAwt9///3Yuogeh4fAiKqAUqnE2LFji7WrVCrxcdGoROfOnZGTk4P//vvvsdsdOnQo7OzsxOedO3cGAFy7du2x64aEhMDX11d83rJlS9jY2IjrajQa7N27F88//zzc3d3Ffn5+fujdu/djtw/o7192djaSk5PRsWNHCIKAU6dOFes/fvx4veedO3fW25edO3fCxMREHBECAIVCgddff71M9RSZPXs2wsPDiy329vYAgCZNmqB169bYuHGjuI5Go8Gvv/6Kfv366e3Xw49TU1ORnp6Ozp07Iyoqqlw1laay35NHJSQk4PTp0xgzZoy4z4DuO9CjRw/s3Lmz2DqGPpuUlBRkZGSU+/0f9s8//yApKQkTJ07Um6fUt29f+Pv7Y8eOHQB0vwMzMzPs378fqampBrdVNFL0xx9/oKCgoFJ1ETEAEVWBBg0awMzMrFj7v//+iwEDBkCtVsPGxgZOTk7iBOr09PTHbrdRo0Z6z4vCUEl/IEpbt2j9onWTkpKQm5sLPz+/Yv0MtRkSHx8v/pEtmtfTpUsXAMX3z9zcvNihtYfrAYC4uDi4ubkVO7TTtGnTMtVTpEWLFggJCSm2PPwZDR06FEeOHBHnoezfvx9JSUkYOnSo3rb++OMPPPnkkzA3N4e9vT2cnJywbNmyMn1+ZVXZ78mj4uLiABj+vQUEBCA5ORnZ2dl67ZX5rlW0Fn9/f/F1pVKJhQsX4s8//4SLiwuefvppfPrpp0hMTBT7d+nSBQMHDsTcuXPh6OiI/v37Y9WqVcjLy6tUjWScGICIqsDD/4IvkpaWhi5duuDMmTOYN28efv/9d4SHh4tzKspy2rtCoTDYLghCta5bFhqNBj169MCOHTvw7rvvYuvWrQgPDxcn4j66fyXVI5WhQ4dCEARxrtKmTZugVqvRq1cvsc+hQ4fw3HPPwdzcHN988w127tyJ8PBwvPjii4/9PZY0idzQpO/Kfk+qQnV/X8piypQpuHTpEhYsWABzc3PMmjULAQEB4miiTCbDr7/+isjISEyePBk3b97Eyy+/jKCgIGRlZdVYnVQ/cBI0UTXZv38/UlJSsHnzZjz99NNie0xMjIRVPeDs7Axzc3NcuXKl2GuG2h517tw5XLp0CWvWrMGoUaPE9vDw8ArX5OnpiYiICGRlZemNAl28eLHC2yyJt7c32rdvj40bN2Ly5MnYvHkznn/+eSiVSrHPb7/9BnNzc+zevVuvfdWqVY/dftEISlpamnjoBngwIlKkPN+Tsl7x29PTE4Dh39t///0HR0dHWFpalmlblfVwLc8884zeaxcvXhRfL+Lr64u3334bb7/9Ni5fvozWrVvj888/x88//yz2efLJJ/Hkk0/io48+wrp16zBixAhs2LAB48aNq/4donqDI0BE1aToX9QP/ws6Pz8f33zzjVQl6VEoFAgJCcHWrVtx69Ytsf3KlSv4888/y7Q+oL9/giDgyy+/rHBNffr0QWFhIZYtWya2aTQahIWFVXibpRk6dCiOHTuGH374AcnJycUOfykUCshkMr1Rm9jYWGzduvWx2y6af3Xw4EGxLTs7G2vWrCn2HkDZvieWlpZlOiTm5uaG1q1bY82aNXqXEDh//jz27NmDPn36PHYbVaVt27ZwdnbG8uXL9Q5V/fnnn4iOjhbPpMvJycG9e/f01vX19YW1tbW4XmpqarERqdatWwMAD4NRuXEEiKiadOzYEXZ2dhg9ejTeeOMNyGQy/PTTTzV6SOFx5syZgz179qBTp06YMGECNBoNli5diubNm+P06dOlruvv7w9fX19MmzYNN2/ehI2NDX777bdKzRnp168fOnXqhBkzZiA2NhbNmjXD5s2byz0P5tChQ8X+mAK6ScAtW7YUnw8ZMgTTpk3DtGnTYG9vj5CQEL3+ffv2xeLFi9GrVy+8+OKLSEpKwtdffw0/Pz+cPXu21Bp69uyJRo0a4X//+x+mT58OhUKBH374AU5OToiPjxf7led7EhQUhI0bN2Lq1Klo164drKys0K9fP4Pv/9lnn6F3797o0KED/ve//4mnwavVasyZM6fU2suroKAAH374YbF2e3t7TJw4EQsXLsTYsWPRpUsXDB8+XDwN3svLC2+99RYA4NKlS+jevTuGDBmCZs2awcTEBFu2bMHt27fFyxKsWbMG33zzDQYMGABfX19kZmbiu+++g42NTY2GOqonJDn3jKiOKuk0+MDAQIP9jxw5Ijz55JOCSqUS3N3dhXfeeUfYvXu3AEDYt2+f2K+k0+ANnRIMQPjggw/E5yWdBj9p0qRi6z56qrYgCEJERITQpk0bwczMTPD19RVWrlwpvP3224K5uXkJv4UHLly4IISEhAhWVlaCo6Oj8Morr4in2z98SnZJp0obqj0lJUUYOXKkYGNjI6jVamHkyJHCqVOnquQ0+Id/b0U6deokABDGjRtncJvff/+90LhxY0GpVAr+/v7CqlWrDNZt6Hd78uRJITg4WDAzMxMaNWokLF682OBp8GX9nmRlZQkvvviiYGtrKwAQvzOGToMXBEHYu3ev0KlTJ0GlUgk2NjZCv379hAsXLuj1KdqXO3fu6LUbqtOQokscGFp8fX3Ffhs3bhTatGkjKJVKwd7eXhgxYoRw48YN8fXk5GRh0qRJgr+/v2BpaSmo1WohODhY2LRpk9gnKipKGD58uNCoUSNBqVQKzs7OwrPPPiv8888/pdZIZIhMEGrRP0eJqFZ4/vnn8e+//+Ly5ctSl0JEVC04B4jIyD1624rLly9j586d6Nq1qzQFERHVAI4AERk5Nzc3jBkzBj4+PoiLi8OyZcuQl5eHU6dOoXHjxlKXR0RULTgJmsjI9erVC+vXr0diYiKUSiU6dOiAjz/+mOGHiOo1jgARERGR0eEcICIiIjI6DEBERERkdDgHyACtVotbt27B2tq6zJeeJyIiImkJgoDMzEy4u7tDLi99jIcByIBbt27Bw8ND6jKIiIioAq5fv46GDRuW2ocByABra2sAul+gjY2NxNUQERFRWWRkZMDDw0P8O14aBiADig572djYMAARERHVMWWZvsJJ0ERERGR0GICIiIjI6DAAERERkdHhHCAiIqo0jUaDgoICqcuges7U1BQKhaJKtsUAREREFSYIAhITE5GWliZ1KWQkbG1t4erqWunr9DEAERFRhRWFH2dnZ1hYWPDisVRtBEFATk4OkpKSAABubm6V2h4DEBERVYhGoxHDj4ODg9TlkBFQqVQAgKSkJDg7O1fqcBgnQRMRUYUUzfmxsLCQuBIyJkXft8rOOWMAIiKiSuFhL6pJVfV9YwAiIiIio8MAREREVEleXl5YsmRJmfvv378fMpmMZ89JiAGIiIiMhkwmK3WZM2dOhbb7999/49VXXy1z/44dOyIhIQFqtbpC71dWDFol41lgNeleum4xtQQsecYEEVFNS0hIEB9v3LgRs2fPxsWLF8U2Kysr8bEgCNBoNDAxefyfSicnp3LVYWZmBldX13KtQ1WLI0A16e/vgSUtgL2zpa6EiMgoubq6iotarYZMJhOf//fff7C2tsaff/6JoKAgKJVKHD58GFevXkX//v3h4uICKysrtGvXDnv37tXb7qOHwGQyGVauXIkBAwbAwsICjRs3xvbt28XXHx2ZWb16NWxtbbF7924EBATAysoKvXr10gtshYWFeOONN2BrawsHBwe8++67GD16NJ5//vkK/z5SU1MxatQo2NnZwcLCAr1798bly5fF1+Pi4tCvXz/Y2dnB0tISgYGB2Llzp7juiBEj4OTkBJVKhcaNG2PVqlUVrqWmMQAREVGVEQQBOfmFNb4IglBl+zBjxgx88skniI6ORsuWLZGVlYU+ffogIiICp06dQq9evdCvXz/Ex8eXup25c+diyJAhOHv2LPr06YMRI0bg7t27JfbPycnBokWL8NNPP+HgwYOIj4/HtGnTxNcXLlyItWvXYtWqVThy5AgyMjKwdevWSu3rmDFj8M8//2D79u2IjIyEIAjo06ePeIr5pEmTkJeXh4MHD+LcuXNYuHChOEo2a9YsXLhwAX/++Seio6OxbNkyODo6VqqemsRDYEREVGVyCzRoNnt3jb/vhXmhsDCrmj9p8+bNQ48ePcTn9vb2aNWqlfh8/vz52LJlC7Zv347JkyeXuJ0xY8Zg+PDhAICPP/4YX331FU6cOIFevXoZ7F9QUIDly5fD19cXADB58mTMmzdPfD0sLAwzZ87EgAEDAABLly4VR2Mq4vLly9i+fTuOHDmCjh07AgDWrl0LDw8PbN26FYMHD0Z8fDwGDhyIFi1aAAB8fHzE9ePj49GmTRu0bdsWgG4UrC7hCBAREdFDiv6gF8nKysK0adMQEBAAW1tbWFlZITo6+rEjQC1bthQfW1pawsbGRryNgyEWFhZi+AF0t3oo6p+eno7bt2+jffv24usKhQJBQUHl2reHRUdHw8TEBMHBwWKbg4MDmjZtiujoaADAG2+8gQ8//BCdOnXCBx98gLNnz4p9J0yYgA0bNqB169Z45513cPTo0QrXIgWOABERUZVRmSpwYV6oJO9bVSwtLfWeT5s2DeHh4Vi0aBH8/PygUqkwaNAg5Ofnl7odU1NTvecymQxarbZc/avy0F5FjBs3DqGhodixYwf27NmDBQsW4PPPP8frr7+O3r17Iy4uDjt37kR4eDi6d++OSZMmYdGiRZLWXFYcASIioiojk8lgYWZS40t1Xo36yJEjGDNmDAYMGIAWLVrA1dUVsbGx1fZ+hqjVari4uODvv/8W2zQaDaKioiq8zYCAABQWFuL48eNiW0pKCi5evIhmzZqJbR4eHhg/fjw2b96Mt99+G9999534mpOTE0aPHo2ff/4ZS5YswYoVKypcT03jCBAREVEpGjdujM2bN6Nfv36QyWSYNWtWqSM51eX111/HggUL4OfnB39/f4SFhSE1NbVM4e/cuXOwtrYWn8tkMrRq1Qr9+/fHK6+8gm+//RbW1taYMWMGGjRogP79+wMApkyZgt69e6NJkyZITU3Fvn37EBAQAACYPXs2goKCEBgYiLy8PPzxxx/ia3UBAxAREVEpFi9ejJdffhkdO3aEo6Mj3n33XWRkZNR4He+++y4SExMxatQoKBQKvPrqqwgNDS3THdGffvppvecKhQKFhYVYtWoV3nzzTTz77LPIz8/H008/jZ07d4qH4zQaDSZNmoQbN27AxsYGvXr1whdffAFAdy2jmTNnIjY2FiqVCp07d8aGDRuqfseriUyQ+gBjLZSRkQG1Wo309HTY2NhU3YYPLQYi5gJtXgL6f1112yUiksC9e/cQExMDb29vmJubS12O0dFqtQgICMCQIUMwf/58qcupMaV978rz95sjQERERHVAXFwc9uzZgy5duiAvLw9Lly5FTEwMXnzxRalLq5M4CZqIiKgOkMvlWL16Ndq1a4dOnTrh3Llz2Lt3b52ad1ObSBqAMjMzMWXKFHh6ekKlUqFjx456M9wftXnzZvTo0QNOTk6wsbFBhw4dsHu3/gW35syZU+zmdv7+/tW9K0RERNXKw8MDR44cQXp6OjIyMnD06NFic3uo7CQNQOPGjUN4eDh++uknnDt3Dj179kRISAhu3rxpsP/BgwfRo0cP7Ny5EydPnkS3bt3Qr18/nDp1Sq9fYGAgEhISxOXw4cM1sTtERERUR0g2Byg3Nxe//fYbtm3bJibYOXPm4Pfff8eyZcvw4YcfFlvn4RvNAbpLi2/btg2///472rRpI7abmJjwLrtERERUIslGgAoLC6HRaIrN4FapVGUesdFqtcjMzIS9vb1e++XLl+Hu7g4fHx+MGDHisZcrz8vLQ0ZGht5CRERE9ZdkAcja2hodOnTA/PnzcevWLWg0Gvz888+IjIxEQkJCmbaxaNEiZGVlYciQIWJbcHAwVq9ejV27dmHZsmWIiYlB586dkZmZWeJ2FixYALVaLS4eHh6V3j8iIiKqvSSdA/TTTz9BEAQ0aNAASqUSX331FYYPHw65/PFlrVu3DnPnzsWmTZvg7Owstvfu3RuDBw9Gy5YtERoaip07dyItLQ2bNm0qcVszZ85Eenq6uFy/fr1K9o+IiIhqJ0mvA+Tr64sDBw4gOzsbGRkZcHNzw9ChQ+Hj41Pqehs2bMC4cePwyy+/ICQkpNS+tra2aNKkCa5cuVJiH6VSCaVSWaF9ICIiorqnVlwHyNLSEm5ubkhNTcXu3bvFe5AYsn79eowdOxbr169H3759H7vtrKwsXL16FW5ublVZMhERUYliY2Mhk8lw+vTpan+v1atXw9bWttrfp76RNADt3r0bu3btQkxMDMLDw9GtWzf4+/tj7NixAHSHpkaNGiX2X7duHUaNGoXPP/8cwcHBSExMRGJiItLT08U+06ZNw4EDBxAbG4ujR49iwIABUCgUGD58eI3vHxER1T5jxowpdr04mUyGXr16SV3aY3l5eRU7I3ro0KG4dOlStb93165dMWXKlGp/n5oi6SGw9PR0zJw5Ezdu3IC9vT0GDhyIjz76SLwJW0JCgt4ZXCtWrEBhYSEmTZqESZMmie2jR4/G6tWrAQA3btzA8OHDkZKSAicnJzz11FM4duwYnJycanTfiIio9urVqxdWrVql11ZXp0KoVCqoVCqpy6hzJB0BGjJkCK5evYq8vDwkJCRg6dKlUKvV4uurV6/G/v37xef79++HIAjFlqLwA+jmB926dQt5eXm4ceMGNmzYAF9f3xrcKyIiqu2USiVcXV31Fjs7OwDAiy++iKFDh+r1LygogKOjI3788UcAwK5du/DUU0/B1tYWDg4OePbZZ3H16tUS38/QYaqtW7dCJpOJz69evYr+/fvDxcUFVlZWaNeuHfbu3Su+3rVrV8TFxeGtt94SR61K2vayZcvg6+sLMzMzNG3aFD/99JPe6zKZDCtXrsSAAQNgYWGBxo0bY/v27WX75ZXgt99+Q2BgIJRKJby8vPD555/rvf7NN9+gcePGMDc3h4uLCwYNGiS+9uuvv6JFixZQqVRwcHBASEgIsrOzK1XP49SKOUBERFRPCAKQn13ziyBU2S6MGDECv//+O7KyssS23bt3IycnBwMGDAAAZGdnY+rUqfjnn38QEREBuVyOAQMGQKvVVvh9s7Ky0KdPH0RERODUqVPo1asX+vXrJx4J2bx5Mxo2bIh58+aJdzowZMuWLXjzzTfx9ttv4/z583jttdcwduxY7Nu3T6/f3LlzMWTIEJw9exZ9+vTBiBEjcPfu3QrVfvLkSQwZMgTDhg3DuXPnMGfOHMyaNUscoPjnn3/wxhtvYN68ebh48SJ27dolXgQ5ISEBw4cPx8svv4zo6Gjs378fL7zwAoQq/EwN4d3giYio6hTkAB+71/z7vncLMLMsc/c//vgDVlZW+pt47z289957CA0NhaWlJbZs2YKRI0cC0M1Bfe6552BtbQ0AGDhwoN66P/zwA5ycnHDhwgU0b968QrvQqlUrtGrVSnw+f/58bNmyBdu3b8fkyZNhb28PhUIBa2vrUu92sGjRIowZMwYTJ04EAEydOhXHjh3DokWL0K1bN7HfmDFjxPmxH3/8Mb766iucOHGiQnOhFi9ejO7du2PWrFkAgCZNmuDChQv47LPPMGbMGMTHx8PS0hLPPvssrK2t4enpKd7BISEhAYWFhXjhhRfg6ekJAGjRokW5aygvjgAREZHR6datG06fPq23jB8/HoDudkpDhgzB2rVrAehGe7Zt24YRI0aI61++fBnDhw+Hj48PbGxs4OXlBQCPvfNAabKysjBt2jQEBATA1tYWVlZWiI6OLvc2o6Oj0alTJ722Tp06ITo6Wq+tZcuW4mNLS0vY2NggKSmpQrWX9J6XL1+GRqNBjx494OnpCR8fH4wcORJr165FTk4OAF3w6969O1q0aIHBgwfju+++Q2pqaoXqKA+OABERUdUxtdCNxkjxvuVgaWkJPz+/El8fMWIEunTpgqSkJISHh0OlUumNjPTr1w+enp747rvv4O7uDq1Wi+bNmyM/P9/g9uRyebFDOgUFBXrPp02bhvDwcCxatAh+fn5QqVQYNGhQidusrKITjorIZLJKHcIrjbW1NaKiorB//37s2bMHs2fPxpw5c/D333/D1tYW4eHhOHr0KPbs2YOwsDC8//77OH78OLy9vaulHoAjQEREVJVkMt2hqJpeHppMXBU6duwIDw8PbNy4EWvXrsXgwYPFwJCSkoKLFy/i//7v/9C9e3cEBAQ8dsTCyckJmZmZehN7H71G0JEjRzBmzBgMGDAALVq0gKurK2JjY/X6mJmZQaPRlPpeAQEBOHLkSLFtN2vW7DF7XXElvWeTJk2gUCgA6EbWQkJC8Omnn+Ls2bOIjY3FX3/9BUAXvjp16oS5c+fi1KlTMDMzw5YtW6qtXoAjQEREZITy8vKQmJio12ZiYgJHR0fx+Ysvvojly5fj0qVLehOI7ezs4ODggBUrVsDNzQ3x8fGYMWNGqe8XHBwMCwsLvPfee3jjjTdw/PhxvTOYAaBx48bYvHkz+vXrB5lMhlmzZhUbkfHy8sLBgwcxbNgwKJVKvXqLTJ8+HUOGDEGbNm0QEhKC33//HZs3b9Y7o6yi7ty5Uyy4ubm54e2330a7du0wf/58DB06FJGRkVi6dCm++eYbALo5V9euXcPTTz8NOzs77Ny5E1qtFk2bNsXx48cRERGBnj17wtnZGcePH8edO3cQEBBQ6XpLJVAx6enpAgAhPT29ajd88HNB+MBGELZOrNrtEhFJIDc3V7hw4YKQm5srdSnlMnr0aAFAsaVp06Z6/S5cuCAAEDw9PQWtVqv3Wnh4uBAQECAolUqhZcuWwv79+wUAwpYtWwRBEISYmBgBgHDq1ClxnS1btgh+fn6CSqUSnn32WWHFihXCw3+GY2JihG7dugkqlUrw8PAQli5dKnTp0kV48803xT6RkZFCy5YtBaVSKa67atUqQa1W69X3zTffCD4+PoKpqanQpEkT4ccff9R7/eFai6jVamHVqlUl/t66dOli8Pc2f/58QRAE4ddffxWaNWsmmJqaCo0aNRI+++wzcd1Dhw4JXbp0Eezs7ASVSiW0bNlS2Lhxo/h7Dg0NFZycnASlUik0adJECAsLK7GO0r535fn7Lbv/i6CHZGRkQK1WIz09HTY2NlW34UOLgYi5QJuXgP5fV912iYgkcO/ePcTExMDb2xvm5uZSl0NGorTvXXn+fnMOEBERERkdBiAiIiIyOgxAREREZHQYgIiIiMjoMAAREVGl8FwaqklV9X1jACIiogopujBg0S0NiGpC0fft0StZlxcvhEhERBWiUChga2sr3j/KwsICsiq+IjNREUEQkJOTg6SkJNja2opXmK4oBiAiIqqworuSV/QmmkTlZWtrK37vKoMBiIiIKkwmk8HNzQ3Ozs7Fbu5JVNVMTU0rPfJThAGIiIgqTaFQVNkfJqKawEnQREREZHQYgIiIiMjoMAARERGR0WEAIiIiIqPDAERERERGhwGIiIiIjA4DEBERERkdBiAiIiIyOgxAREREZHQYgIiIiMjoMAARERGR0WEAIiIiIqPDAERERERGhwGIiIiIjA4DEBERERkdBiAiIiIyOgxAREREZHQYgIiIiMjoMAARERGR0WEAIiIiIqMjaQDKzMzElClT4OnpCZVKhY4dO+Lvv/8udZ39+/fjiSeegFKphJ+fH1avXl2sz9dffw0vLy+Ym5sjODgYJ06cqKY9ICIiorpI0gA0btw4hIeH46effsK5c+fQs2dPhISE4ObNmwb7x8TEoG/fvujWrRtOnz6NKVOmYNy4cdi9e7fYZ+PGjZg6dSo++OADREVFoVWrVggNDUVSUlJN7RYRERHVcjJBEAQp3jg3NxfW1tbYtm0b+vbtK7YHBQWhd+/e+PDDD4ut8+6772LHjh04f/682DZs2DCkpaVh165dAIDg4GC0a9cOS5cuBQBotVp4eHjg9ddfx4wZM8pUW0ZGBtRqNdLT02FjY1OZ3dR3aDEQMRdo8xLQ/+uq2y4RERGV6++3ZCNAhYWF0Gg0MDc312tXqVQ4fPiwwXUiIyMREhKi1xYaGorIyEgAQH5+Pk6ePKnXRy6XIyQkROxjSF5eHjIyMvQWIiIiqr8kC0DW1tbo0KED5s+fj1u3bkGj0eDnn39GZGQkEhISDK6TmJgIFxcXvTYXFxdkZGQgNzcXycnJ0Gg0BvskJiaWWMuCBQugVqvFxcPDo/I7SERERLWWpHOAfvrpJwiCgAYNGkCpVOKrr77C8OHDIZfXbFkzZ85Eenq6uFy/fr1G35+IiIhqlomUb+7r64sDBw4gOzsbGRkZcHNzw9ChQ+Hj42Owv6urK27fvq3Xdvv2bdjY2EClUkGhUEChUBjs4+rqWmIdSqUSSqWy8jtEREREdUKtuA6QpaUl3NzckJqait27d6N///4G+3Xo0AERERF6beHh4ejQoQMAwMzMDEFBQXp9tFotIiIixD5EREREkgag3bt3Y9euXYiJiUF4eDi6desGf39/jB07FoDu0NSoUaPE/uPHj8e1a9fwzjvv4L///sM333yDTZs24a233hL7TJ06Fd999x3WrFmD6OhoTJgwAdnZ2eI2iYiIiCQ9BJaeno6ZM2fixo0bsLe3x8CBA/HRRx/B1NQUAJCQkID4+Hixv7e3N3bs2IG33noLX375JRo2bIiVK1ciNDRU7DN06FDcuXMHs2fPRmJiIlq3bo1du3YVmxhNRERExkuy6wDVZrwOEBERUd1TJ64DRERERCQVBiAiIiIyOgxAREREZHQYgIiIiMjoMAARERGR0WEAIiIiIqPDAERERERGhwGIiIiIjA4DEBERERkdBqCapDDT/Uw8D2gKpa2FiIjIiDEA1aRm/QGlDZBwGji0SOpqiIiIjBYDUE2y9QD6LtY9PrAQiD8mbT1ERERGigGoprUcDLQcCgha4LdXgHvpUldERERkdBiApNBnEWDrCaTHAzvelroaIiIio8MAJAVzG2Dg94BMAZz7BTizUeqKiIiIjAoDkFQ82gFdZ+ge73gbuBsjbT1ERERGhAFISp3fBhp1APIzgc2vAJoCqSsiIiIyCgxAUpIrgBdWAEo1cONv4MCnUldERERkFBiApGbbCHj2/qnxhxYBcUelrYeIiMgIMADVBi0GAa1e1J0av/lVIDdN6oqIiIjqNQag2qLPp4CdN5B+HfjjLUAQpK6IiIio3mIAqi2U1sDAlbpT4//dDJxZL3VFRERE9RYDUG3SsC3Q7T3d453TgZSr0tZDRERUTzEA1TZPvQV4PgXkZ/HUeCIiomrCAFTbyBXAC98C5mrg5klg/ydSV0RERFTvMADVRuqGQL8vdY8PfQ7EHpa2HiIionqGAai2ChwAtHkJgHD/1PhUqSsiIiKqNxiAarNeCwF7XyDjJvD7FJ4aT0REVEUYgGozpRUw8DtAbgJc2AqcXit1RURERPUCA1Bt1yAI6Pa+7vHOd3hqPBERURVgAKoLOr0JeHUGCrKB3/4HFOZLXREREVGdxgBUF8gVwIBvAXNb4NYpYP/HUldERERUpzEA1RXqBsBzYbrHh5cAMQclLYeIiKguYwCqS5o9BzwxCrpT418Dcu5KXREREVGdxABU1/T6BHDwAzJvAb+/wVPjiYiIKoABqK4xswQGfg/ITYHo34GoH6WuiIiIqM5hAKqL3FsD3WfpHu+aASRflrQcIiKiuoYBqK7q8Drg3QUoyOGp8UREROXEAFRXyeXAgOWAyh5IOAP8NV/qioiIiOoMSQOQRqPBrFmz4O3tDZVKBV9fX8yfPx9CKRN7x4wZA5lMVmwJDAwU+8yZM6fY6/7+/jWxSzXLxh3ov1T3+OhXwLX9kpZDRERUV0gagBYuXIhly5Zh6dKliI6OxsKFC/Hpp58iLCysxHW+/PJLJCQkiMv169dhb2+PwYMH6/ULDAzU63f48OHq3h1p+PcFgsbqHm8ZD2SnSFsPERFRHWAi5ZsfPXoU/fv3R9++fQEAXl5eWL9+PU6cOFHiOmq1Gmq1Wny+detWpKamYuzYsXr9TExM4OrqWj2F1zahHwNxR4DkS8D214FhawGZTOqqiIiIai1JR4A6duyIiIgIXLp0CQBw5swZHD58GL179y7zNr7//nuEhITA09NTr/3y5ctwd3eHj48PRowYgfj4+BK3kZeXh4yMDL2lTjGzAAau1J0af3EHcHKV1BURERHVapIGoBkzZmDYsGHw9/eHqakp2rRpgylTpmDEiBFlWv/WrVv4888/MW7cOL324OBgrF69Grt27cKyZcsQExODzp07IzMz0+B2FixYII4sqdVqeHh4VHrfapxbKyBkju7xrveAOxclLYeIiKg2kwmlzTiuZhs2bMD06dPx2WefITAwEKdPn8aUKVOwePFijB49+rHrL1iwAJ9//jlu3boFMzOzEvulpaXB09MTixcvxv/+979ir+fl5SEvL098npGRAQ8PD6Snp8PGxqZiOycFrRZYOxC4+hfg2gIYFwGYKKWuioiIqEZkZGRArVaX6e+3pHOApk+fLo4CAUCLFi0QFxeHBQsWPDYACYKAH374ASNHjiw1/ACAra0tmjRpgitXrhh8XalUQqmsB0FBLgeeXwYs6wgkngMi5gGhH0ldFRERUa0j6SGwnJwcyOX6JSgUCmi12seue+DAAVy5csXgiM6jsrKycPXqVbi5uVW41jrD2hV47v6p8ZFLgSsR0tZDRERUC0kagPr164ePPvoIO3bsQGxsLLZs2YLFixdjwIABYp+ZM2di1KhRxdb9/vvvERwcjObNmxd7bdq0aThw4ABiY2Nx9OhRDBgwAAqFAsOHD6/W/ak1/PsA7e7Pi9o6AchOlrYeIiKiWkbSQ2BhYWGYNWsWJk6ciKSkJLi7u+O1117D7NmzxT4JCQnFzuBKT0/Hb7/9hi+//NLgdm/cuIHhw4cjJSUFTk5OeOqpp3Ds2DE4OTlV6/7UKj0/BGIPA3f+A7ZNBoav56nxRERE90k6Cbq2Ks8kqlot8TzwXTdAkw/0/fzBqBAREVE9VJ6/37wXWH3m2hwImat7vPt9ICla2nqIiIhqCQag+i54POAXAhTeA34bBxTck7oiIiIiyTEA1XdFp8ZbOAK3zwMRc6WuiIiISHIMQMbAyhl4/hvd42PfAJf3SlsPERGRxBiAjEWTUKD9q7rHWycAWXekrYeIiEhCDEDGpMc8wLkZkJ0EbJsI8ARAIiIyUgxAxsRUBQz8HlAogct7gBPfSV0RERGRJBiAjI1LM6DnfN3jPf8H3L4gbT1EREQSYAAyRu1fBRr3BDR5wG//Awpypa6IiIioRjEAGSOZDOj/DWDpDCRdAMI/kLoiIiKiGsUAZKysnHTXBwKAE98Cl/ZIWw8REVENYgAyZo1DgOAJusfbJgJZSdLWQ0REVEMYgIxdyBzApTmQfUd3fSCtVuqKiIiIqh0DkLEzNQcGrgRMzIEre3WHw4iIiOo5BiACnAOAnh/qHofPBhLPS1sPERFRNWMAIp1244AmvQFNPk+NJyKieo8BiHRkMqD/UsDKBbjzn+4iiURERPUUAxA9YOn44NT4v1cCF/+Uth4iIqJqwgBE+vy6Ax0m6x5vmwRkJkpbDxERUTVgAKLius8GXFsAOSk8NZ6IiOolBiAqzkSpu2u8iQq4+hdwfJnUFREREVUpBiAyzKkpEPqR7vHeOUDCWUnLISIiqkoMQFSyti8DTfs+ODU+P0fqioiIiKoEAxCVTCYDngsDrFyB5EvAnvelroiIiKhKMABR6SwdgAHLdY//+QH4b4e09RAREVUBBiB6PN9uQMfXdY+3TQYyEqSth4iIqJIYgKhsnpkNuLUCcu8CW17jqfFERFSnMQBR2ZiY6U6NN7UAYg4AkUulroiIiKjCGICo7BwbA70W6B5HzANunZa0HCIioopiAKLyeWI04P8soC0AjiyRuhoiIqIKYQCi8pHJdAEIAPIypa2FiIioghiAiIiIyOgwABEREZHRYQAiIiIio8MAREREREaHAYiIiIiMToUC0PXr13Hjxg3x+YkTJzBlyhSsWLGiygojIiIiqi4VCkAvvvgi9u3bBwBITExEjx49cOLECbz//vuYN29elRZIREREVNUqFIDOnz+P9u3bAwA2bdqE5s2b4+jRo1i7di1Wr15d5u1oNBrMmjUL3t7eUKlU8PX1xfz58yEIQonr7N+/HzKZrNiSmJio1+/rr7+Gl5cXzM3NERwcjBMnTlRkV4mIiKgeMqnISgUFBVAqlQCAvXv34rnnngMA+Pv7IyGh7HcKX7hwIZYtW4Y1a9YgMDAQ//zzD8aOHQu1Wo033nij1HUvXrwIGxsb8bmzs7P4eOPGjZg6dSqWL1+O4OBgLFmyBKGhobh48aJePyIiIjJOFRoBCgwMxPLly3Ho0CGEh4ejV69eAIBbt27BwcGhzNs5evQo+vfvj759+8LLywuDBg1Cz549yzRa4+zsDFdXV3GRyx/syuLFi/HKK69g7NixaNasGZYvXw4LCwv88MMP5d9ZIiIiqncqFIAWLlyIb7/9Fl27dsXw4cPRqlUrAMD27dvFQ2Nl0bFjR0RERODSpUsAgDNnzuDw4cPo3bv3Y9dt3bo13Nzc0KNHDxw5ckRsz8/Px8mTJxESEiK2yeVyhISEIDIy0uC28vLykJGRobcQERFR/VWhQ2Bdu3ZFcnIyMjIyYGdnJ7a/+uqrsLCwKPN2ZsyYgYyMDPj7+0OhUECj0eCjjz7CiBEjSlzHzc0Ny5cvR9u2bZGXl4eVK1eia9euOH78OJ544gkkJydDo9HAxcVFbz0XFxf8999/Bre5YMECzJ07t8x1ExERUd1WoQCUm5sLQRDE8BMXF4ctW7YgICAAoaGhZd7Opk2bsHbtWqxbtw6BgYE4ffo0pkyZAnd3d4wePdrgOk2bNkXTpk3F5x07dsTVq1fxxRdf4KeffqrI7mDmzJmYOnWq+DwjIwMeHh4V2hYRERHVfhUKQP3798cLL7yA8ePHIy0tDcHBwTA1NUVycjIWL16MCRMmlGk706dPx4wZMzBs2DAAQIsWLRAXF4cFCxaUGIAMad++PQ4fPgwAcHR0hEKhwO3bt/X63L59G66urgbXVyqV4qRuIiIiqv8qNAcoKioKnTt3BgD8+uuvcHFxQVxcHH788Ud89dVXZd5OTk6O3uRlAFAoFNBqteWq5/Tp03BzcwMAmJmZISgoCBEREeLrWq0WERER6NChQ7m2S0RERPVThUaAcnJyYG1tDQDYs2cPXnjhBcjlcjz55JOIi4sr83b69euHjz76CI0aNUJgYCBOnTqFxYsX4+WXXxb7zJw5Ezdv3sSPP/4IAFiyZAm8vb0RGBiIe/fuYeXKlfjrr7+wZ88ecZ2pU6di9OjRaNu2Ldq3b48lS5YgOzsbY8eOrcjuUj0mCALyNVooTRRSl0JERDWoQgHIz88PW7duxYABA7B792689dZbAICkpCS9a/M8TlhYGGbNmoWJEyciKSkJ7u7ueO211zB79myxT0JCAuLj48Xn+fn5ePvtt3Hz5k1YWFigZcuW2Lt3L7p16yb2GTp0KO7cuYPZs2cjMTERrVu3xq5du4pNjCbjdjLuLub9EY02HraY81yg1OUQEVENkgmlXXa5BL/++itefPFFaDQaPPPMMwgPDwegO5vq4MGD+PPPP6u80JqUkZEBtVqN9PT0cgU6o3F6PbB1POAXArz0m9TVVNiRK8kYsfI4lCZyHHqnG5xtzKUuiYiIKqE8f78rNAdo0KBBiI+Pxz///IPdu3eL7d27d8cXX3xRkU0S1biOvg4I8rRDXqEWKw5ek7ocIiKqQRUKQADg6uqKNm3a4NatW+Kd4du3bw9/f/8qK46oOslkMrzRvTEA4OfjcbiTmSdxRUREVFMqFIC0Wi3mzZsHtVoNT09PeHp6wtbWFvPnzy/3GVxEUnq6sSNaedjiXoEWKw9xFIiIyFhUKAC9//77WLp0KT755BOcOnUKp06dwscffyxOaiaqK2QyGd7s7gcA+DEyDilZHAUiIjIGFToLbM2aNVi5cqV4F3gAaNmyJRo0aICJEyfio48+qrICiapbt6bOaN7ABudvZuD7wzF4pxcP4xIR1XcVGgG6e/euwbk+/v7+uHv3bqWLIqpJMpkMbzyjmwu05mgs0nLyJa6IiIiqW4UCUKtWrbB06dJi7UuXLkXLli0rXRRRTevRzAUBbjbIztfgh8MxUpdDRETVrEKHwD799FP07dsXe/fuFW8vERkZievXr2Pnzp1VWiBRTdCNAvlhwtoorDoSi/919oFaZSp1WUREVE0qNALUpUsXXLp0CQMGDEBaWhrS0tLwwgsv4N9//63wHdmJpBYa6IomLlbIzCvE6iOxUpdDRETVqEJXgi7JmTNn8MQTT0Cj0VTVJiXBK0E/Rj25ErQhv5+5hdfXn4KNuQmOzHgG1uYcBSIiqiuq/UrQRPVVnxZu8HWyRMa9QvwYWfYb+xIRUd3CAET0EIVchtfvnxH23aFryMorlLgiIiKqDgxARI/o18odPo6WSMspwM/HOApERFQflesssBdeeKHU19PS0ipTC1GtoJDLMKmbH97+5Qy+O3gNozp4wsKsQidMEhFRLVWuESC1Wl3q4unpiVGjRlVXrUQ1pn9rdzSyt0BKdj7WHouXuhwiIqpi5fpn7apVq6qrDqJaxUQhx+Rufnjnt7P49uA1vPSkJ1RmCqnLIiKiKsI5QEQlGPBEAzSwVSE5Kw/rT3AUiIioPmEAIiqBqUKOSd10d4pffuAq7hXU7etbERHRAwxARKUYGNQA7mpzJGXmYdM/16Uuh4iIqggDEFEplCYKTOjqCwBYtv8q8go5CkREVB8wABE9xuC2HnCxUSIh/R5+PXlD6nKIiKgKMAARPYa5qQLju+hGgb7ZdxX5hVqJKyIiospiACIqg+HtG8HRSombabnYcoqjQEREdR0DEFEZ6EaBfAAAS/ddQYGGo0BERHUZAxBRGb0Y3AgOlma4fjcX207fkrocIiKqBAYgojKyMDPBq0/rRoG+3ncFhRwFIiKqsxiAiMrhpSc9YWdhipjkbPxxNkHqcoiIqIIYgIjKwVJpgnGddaNAX/11GRqtIHFFRERUEQxAROU0qoMn1CpTXLuTjR3nOApERFQXMQARlZO1uSn+95Q3ACAs4jK0HAUiIqpzGICIKmB0Ry9Ym5vgclIWdv2bKHU5RERUTgxARBWgVplibCfdKNBXHAUiIqpzGICIKujlTl6wUprgv8RMhEfflrocIiIqBwYgogqytTDD6I6eAHSjQILAUSAiorqCAYioEv73lA8szBT491YG/vovSepyiIiojBiAiCrB3tIMIztwFIiIqK5hACKqpFc6+8DcVI4zN9Jx4NIdqcshIqIyYAAiqiRHKyVeCtaNAn3JUSAiojqBAYioCrzaxQdKEzlOxafhyJUUqcshIqLHkDQAaTQazJo1C97e3lCpVPD19cX8+fNL/Rf05s2b0aNHDzg5OcHGxgYdOnTA7t279frMmTMHMplMb/H396/u3SEj5mxtjheDGwEAvoy4xFEgIqJaTtIAtHDhQixbtgxLly5FdHQ0Fi5ciE8//RRhYWElrnPw4EH06NEDO3fuxMmTJ9GtWzf069cPp06d0usXGBiIhIQEcTl8+HB17w4ZufFdfGFmIsffsamIvMZRICKi2sxEyjc/evQo+vfvj759+wIAvLy8sH79epw4caLEdZYsWaL3/OOPP8a2bdvw+++/o02bNmK7iYkJXF1dq6VuIkNcbMwxrJ0HfoyMw1cRl9HR11HqkoiIqASSjgB17NgRERERuHTpEgDgzJkzOHz4MHr37l3mbWi1WmRmZsLe3l6v/fLly3B3d4ePjw9GjBiB+Pj4EreRl5eHjIwMvYWoIsZ38YWpQoZj1+7iOEeBiIhqLUkD0IwZMzBs2DD4+/vD1NQUbdq0wZQpUzBixIgyb2PRokXIysrCkCFDxLbg4GCsXr0au3btwrJlyxATE4POnTsjMzPT4DYWLFgAtVotLh4eHpXeNzJO7rYqDG6r+/6E/XVF4mqIiKgkkgagTZs2Ye3atVi3bh2ioqKwZs0aLFq0CGvWrCnT+uvWrcPcuXOxadMmODs7i+29e/fG4MGD0bJlS4SGhmLnzp1IS0vDpk2bDG5n5syZSE9PF5fr169Xyf6RcZrQxRcmchkOX0nGybi7UpdDREQGSBqApk+fLo4CtWjRAiNHjsRbb72FBQsWPHbdDRs2YNy4cdi0aRNCQkJK7Wtra4smTZrgyhXD/yJXKpWwsbHRW4gqysPeAgOfaAgA+CqCo0BERLWRpAEoJycHcrl+CQqFAlqtttT11q9fj7Fjx2L9+vXiBOrSZGVl4erVq3Bzc6tUvURlNbGbLxRyGQ5cuoPT19OkLoeIiB4haQDq168fPvroI+zYsQOxsbHYsmULFi9ejAEDBoh9Zs6ciVGjRonP161bh1GjRuHzzz9HcHAwEhMTkZiYiPT0dLHPtGnTcODAAcTGxuLo0aMYMGAAFAoFhg8fXqP7R8bL08ESz7duAAAIi7gscTVERPQoSQNQWFgYBg0ahIkTJyIgIADTpk3Da6+9hvnz54t9EhIS9M7gWrFiBQoLCzFp0iS4ubmJy5tvvin2uXHjBoYPH46mTZtiyJAhcHBwwLFjx+Dk5FSj+0fGbVI3X8hlQMR/STh/M/3xKxARUY2RCbxkbTEZGRlQq9VIT0/nfCBDTq8Hto4H/EKAl36TuppabcqGU9h6+hZ6NnPBilFtpS6HiKheK8/fb94LjKgaTX7GDzIZsOfCbVy4xetLERHVFgxARNXIz9kaz7Z0BwAs3ce5QEREtQUDEFE1e/0ZPwDAznOJuJho+GKcRERUsxiAiKpZExdr9Gmhuy9d2F8cBSIiqg0YgIhqwORujQEAO84l4EoSR4GIiKTGAERUA5q526BnMxcIArCU9wgjIpIcAxBRDXmju24UaPuZW7h2J0viaoiIjBsDEFENad5Aje7+ztAKwNf7rkpdDhGRUWMAIqpBr98fBdp6+ibiUrIlroaIyHgxABHVoNYetujSxAkarYBvOApERCQZBiCiGlY0F+i3qBu4fjdH4mqIiIwTAxBRDQvytMNTfo4o1ApYdoCjQEREUmAAIpJA0SjQL/9cx620XImrISIyPgxARBJo722PJ33sUaARsJyjQERENY4BiEgib3ZvAgDYcOI6EtPvSVwNEZFxYQAiksiTPvZo72WPfI0W3x7kKBARUU1iACKSiEwmE+cCrTsej6RMjgIREdUUBiAiCXXyc8ATjWyRV6jFigPXpC6HiMhoMAARSejhUaCfj8chOStP4oqIiIwDAxCRxLo0cUKrhmrcK9Diu0McBSIiqgkMQEQSe3gU6KfIONzNzpe4IiKi+o8BiKgWeMbfGYHuNsjJ1+D7wxwFIiKqbgxARLXAw6NAa47GIS2Ho0BERNWJAYiolugR4AJ/V2tk5RXihyOxUpdDRFSvMQAR1RJy+YNRoFVHYpCeWyBxRURE9RcDEFEt0ivQFY2drZB5rxBrjsZKXQ4RUb3FAERUi8jlMrx+fxTo+8MxyLzHUSAiourAAERUy/Rt4QZfJ0uk5xbgx8g4qcshIqqXGICIahmFXIbXn9GNAq08dA3ZeYUSV0REVP8wABHVQs+2dIO3oyVScwrw8zGOAhERVTUGIKJayEQhx6RufgCAFQevISefo0BERFWJAYiolurf2h2N7C2Qkp2PdcfjpS6HiKheYQAiqqVMFXJM6uYLAFh+4BruFWgkroiIqP5gACKqxQa0aYgGtiokZ+Vh/QmOAhERVRUGIKJazMxEjoniKNBVjgIREVURBiCiWm5QUEO4qc1xOyMPv/xzXepyiIjqBQYgolpOaaLAhK66UaBv9l9FXiFHgYiIKosBiKgOGNLWA87WSiSk38NvJ29KXQ4RUZ0naQDSaDSYNWsWvL29oVKp4Ovri/nz50MQhFLX279/P5544gkolUr4+flh9erVxfp8/fXX8PLygrm5OYKDg3HixIlq2gui6mduqsD4LrpRoK/3XUGBRitxRUREdZukAWjhwoVYtmwZli5diujoaCxcuBCffvopwsLCSlwnJiYGffv2Rbdu3XD69GlMmTIF48aNw+7du8U+GzduxNSpU/HBBx8gKioKrVq1QmhoKJKSkmpit4iqxYvBjeBopcTNtFxsieIoEBFRZUgagI4ePYr+/fujb9++8PLywqBBg9CzZ89SR2uWL18Ob29vfP755wgICMDkyZMxaNAgfPHFF2KfxYsX45VXXsHYsWPRrFkzLF++HBYWFvjhhx9qYreIqoVuFMgHALB03xUUchSIiKjCJA1AHTt2REREBC5dugQAOHPmDA4fPozevXuXuE5kZCRCQkL02kJDQxEZGQkAyM/Px8mTJ/X6yOVyhISEiH0elZeXh4yMDL2FqDZ6MbgRHCzNEH83B9tO35K6HCKiOkvSADRjxgwMGzYM/v7+MDU1RZs2bTBlyhSMGDGixHUSExPh4uKi1+bi4oKMjAzk5uYiOTkZGo3GYJ/ExESD21ywYAHUarW4eHh4VH7niKqBhZkJXnn6wSiQRlv6fDkiIjJM0gC0adMmrF27FuvWrUNUVBTWrFmDRYsWYc2aNTVax8yZM5Geni4u16/zWitGI/0moK1bp5WPfNITdhamiEnOxu9nOApERFQRJlK++fTp08VRIABo0aIF4uLisGDBAowePdrgOq6urrh9+7Ze2+3bt2FjYwOVSgWFQgGFQmGwj6urq8FtKpVKKJXKKtgjqlPiIoFVvXSP56RLW0s5WCpNMK6zDz7bfRFhf11Gv1buUMhlUpdFRFSnSBqAcnJyIJfrD0IpFApotSVP7uzQoQN27typ1xYeHo4OHToAAMzMzBAUFISIiAg8//zzAACtVouIiAhMnjy5aneAai+tFriXBuTcBXJSDCx3gdM/S11lhY3q4IlvD1zF1TvZ2HkuAf1auUtdEhFRnSJpAOrXrx8++ugjNGrUCIGBgTh16hQWL16Ml19+Wewzc+ZM3Lx5Ez/++CMAYPz48Vi6dCneeecdvPzyy/jrr7+wadMm7NixQ1xn6tSpGD16NNq2bYv27dtjyZIlyM7OxtixY2t8H6kKCAKQn6UfXh4NNNnJ+u25dwGh/p4lZW1uiv895YMv9l5C2F+X0beFG+QcBSIiKjNJA1BYWBhmzZqFiRMnIikpCe7u7njttdcwe/ZssU9CQgLi4x/cBdvb2xs7duzAW2+9hS+//BINGzbEypUrERoaKvYZOnQo7ty5g9mzZyMxMRGtW7fGrl27ik2MJokU3DM8IiM+Ti7epsmv2Hsp1YCFPWDh8NBy/3niOeDfzYCdV5XuXk0Z08kLKw9dw6XbWdj9byJ6t3CTuiQiojpDJjzusstGKCMjA2q1Gunp6bCxsZG6nNrn9Hpg63jALwQYvgHITS35MFN2cvGQU5Bdsfc1MQcsHB8EGEvH4qHm4UVlD5iYlby9q/uAn54HXJoDE45UrCaJLd5zEV/9dQX+rtbY+UZnjgIRkVErz99vSUeAqI7KvH/m0ZW9wHzHim1DbmJ4VEZcHIu3mVlU3T7UEy8/5Y3vD8fgv8RM7I2+jZ6Bhif6ExGRPgYgKr+Yg480yACV7f3QUsqIjIUDYHn/p9IGkHG0orJsLcwwuqMXvtl/FRPWRsHVxhwN7FRoaKtCQzsVGtip0MDWAg3tVHCzNYfSRCF1yUREtQIDEJXfw0dNp18FzG0BBb9KUhnX2Qfbz9zCjdRc3EzTLYZuJiOTAc7WSjSwVaGBnS4U6R6r4HE/KKnMGJCIyDjwrxaVX8O2QMwB3WPLCh4Coypjb2mGg9O7ITkrD9eLQlBqLm6k5uBmWq4uGKXmIrdAg9sZebidkYeo+LQSt1UUjB4EJAtxNMnG3LRmd46IqJowAFH5PTMLUHsAAf2krqRq3D4PfNkKkMkBmeL+z4cW+SPP9frI7vd5dD3Fg9fE7TzaR1b8/eQGtl2GmuQyBZz9usPZMwBBnnbFdlEQBKTmFOhC0f2QdCO1aNEFpcx7hbibnY+72fk4e8PwhSGtzU3Q0M5CDEgPwpIFGtipYGdhChkPbRJRHcCzwAzgWWBG4m4MEBYECHXrVhglcmgMvP5PhVdPzy0Qw9HN1By9Q2o3UnNxN/vxlyJQmSoemnv0IBg1sNUdZnO0UvJMNSKqNjwLjKgs7L2Bt84DGbd0F03UanQ/xaXoufCgrVgfA0uxPsJD23q0n2Dg/R7u8+j2DWz79r9AwmndxR8rQa0yhVplimbuhv+nkZNfqDu0Jh5i0w9LSZl5yC3Q4HJSFi4nZRnchplCLgaiBnoTtVVoaG8BF2slTBSS3qKQiIwEAxAZNxt33VKXJf0HfBNc7W9jYWaCxi7WaOxibfD1ewUaJKTfuz+KlCPOPSoKTAnpucjXaBGTnI2YZMPXglLIZXC1MReDUUM7CzS0LXqsgptaBTMTBiQiqjwGIKL6IidFd4kCuQkgN9XNJ5Kb6BbFI89LXCoeLsxNFfB2tIS3o6XB1ws1WiRm3HsQjO4HpaJDbLfSclGgEcTDbogpvo2iM9mK5iE10JuHxDPZiKjsGICI6jrZQ6FlTSUnpsvkD4WhR0PUo2FJcb/PQ88VpiW+biJXoKHcBA3FPgrA1gSw1z3XyhTILgRu2rTBRVP/hw6xPZiofa9AK57JdjIu1eAuOBSdyfbwPKSHwpI1z2QjIjAAEdV9Dn5Ay2G6uUDaAkBbeH/R6H5qCvSfF/UxRNDq7rtW0XuvVYIcgDUAf6UN/N+N1QWkh0sTBNzNzjcYjIpGlTLzCpGSnY+U7HycKeFMNhtzE73rID04m03XZssz2YiMAs8CM4BngVG9VzT52mBAKgpJDz3XFBh4vbSQVdZtPPQ8JwW4sE1X36xk3WhSOaXnFj/V/8HjHKTmFDx2GxZmikcmaFs8NCdJBUdLnslGVFvxLDAiKl3RNYjkCsBEKXU1OrlpDwJQBenOZFMj0F1t8PXsvMIHo0f3Q9HDYelOZh5y8h9zJpuJXP9CkbYqNLR/EJRcbMyhYEAiqvUYgIjIaFgqTdDExRpNSjmT7Vbaw4fY9A+3JWbcQ35h6WeymchlcFWbw8/ZCsHeDnjSxx4tGqh5ej9RLcMARER0n7mpAj5OVvBxsjL4eoFGi8T0e2IwenQEKSFddyZb0VW291+8AwCwUpqgnZcdnvRxQAdfBwS6qzlKRCQxBiAiojIyVcjhYW8BD3sLg69rtALuZObhRmoOzt5Ix7FrKTgecxfpuQXYd/EO9t0PRNZKE7T3tkcHXwc86eOAADcbBiKiGsZJ0AZwEjSRBHLTgIWeusevHQSU1oCJCjA11/00UermLtUxGq2A6IQMHLuWIgaizHv6Z+GpVaa6QOSjC0T+rtacaE1UAeX5+80AZAADEJEE7qUDnzQqpYMMMFUBJuaGf5b4msWDEPXwT1NV8TYT1YNtKcyqJXBptAIu3MpA5LVkRF5Nwd+xqcjK0w9EthamCL4fiDr4OqKxsxUDEVEZMABVEgMQkUS2TQKuHQAKcoHCe0BBju50fUnIDASsoqBUhoDl/gTg3fmx71Ko0eL8Ld0IkS4Q3UVOvv4Neu0tzfCkz4MRIj9nK16riMgABqBKYgAiqiUEQXf9oMJcoODeg58FOfcDUm7xnyW2PbKNwvvtj7ZVVeCSmwDTrwAqu3KtVqDR4tzNdERe1R0y+yc2FbkF+oHI0UqJJ33sxUnVPo6WDEREYACqNAYgIiNVFLhKDFg594PSYwJW1I+6IDXlHGBb2mG9x8sv1OLsjTRdIIrRBaK8Qv2Q5mytFMNQBx8HeDpYMBCRUWIAqiQGICKqlA9ddOGoCgLQo/IKNTgdn4Zj1+4i8loyouLTkP9IIHK1Mb9/hpk9Ovg4wsNexUBERoEBqJIYgIioUqoxAD3qXoEGp+LTEHn/LLPT8WnI1+gHoga2KgT7FE2qdkBDO8On8RPVdbwVBhGRkTA3VegOffk6AABy8zWIik8V5xCdvp6Gm2m52Bx1E5ujbgIAGtqpxDD0pI8D3G1VUu4CkSQYgIiI6hGVmQKd/BzRyc8RAJCTX4iTcbpAFHktBWdvpONGai5+OXkDv5y8AQDwdLAQzzDr4OsAFxtzKXeBqEYwABER1WMWZibo3NgJnRs7AQCy8grxT+zd+4fM7uLcjTTEpeQgLiUHG/6+DgDwcbREsDhCZA9nawYiqn8YgIiIjIiV0gRdmzqja1NnAEDmvQL8HXtXN6n6agr+vZWOa8nZuJacjfUn4gEAvk6W4uGyJ30c4GillHIXiKoEAxARkRGzNjfFM/4ueMbfBQCQnluAv2N0I0SRV1MQnZiBq3eycfVONn4+pgtETVysdIfLfBwQ7OMAe0szKXeBqEIYgIiISKRWmSKkmQtCmukCUVpOPo7H3BWvVP1fYiYu3c7CpdtZ+DEyDgDg72otzh8K9raHrQUDEdV+PA3eAJ4GT0SVUnQavPsTgIWD7saujy5mVvcf2wBKq+LtClOp98Kgu9n5OBGTIk6qvnQ7S+91mQwIcLURD5m197aHWlU794XqH14HqJIYgIioUpa2B5IvVm4bJir9YKS0eSg0WT/02qPtj4QsMytALq+a/TIgOSsPx+9flPHYtbu4klQ8EAW624in3bf1soeNOQMRVQ8GoEpiACKiSslNA26eBPKzgLxMIK/oZ8ZDbUXtGbrHRe2F96q+HjNrw6NMSptHwpT1/b4PhSw7r3Ldzywp8x6OXdMdMjt2NQXXkrP1XpfLgBYN1Hjy/ghROy97WCk5G4OqBgNQJTEAEZFkNAUPBaTMh8JRxiNhKhPIz3wkTD3Sri2sfD2mlsCbpwEr5wqtnph+D8fvHzI7di0FsSk5eq8r5DK0bKgWJ1W39bKDhRkDEVUMA1AlMQARUZ0nCLrRJEOjTEWjUXqhyUDISrkCCBrgf+GAR/sqKetWWq44ofpYTAqu383Ve91ELkMrD1vxkNkTjeygMlNUyXtT/ccAVEkMQEREAL5sBaTGVmkAetSN1Jz7o0O6w2Y30/QDkZlCjtYetnjSxx5P3g9E5qYMRGQY7wVGRER1QkM7Cwxua4HBbT0gCAJupOaKZ5hFXk1BYsY9nIi9ixOxd/HVX1dgZiJHGw9b3f3PfBzQupEtlCYMRFR+DEBERFQryGQyeNhbwMPeAkPa6QJRXEqOeKf7yKspSMrMw/GYuzgecxdLcBlKEzmCPO109zLzdUCrhrYwM6m+s96o/mAAIiKiWkkmk8HL0RJejpYY3r4RBEHAteTsB3OIrt1FclYejl5NwdGrKUA4oDJVoK2XnXjbjpYN1TBVMBBRcQxARERUJ8hkMvg6WcHXyQojgj0hCAKu3snSm0OUkp2PQ5eTcehyMgDAwkyBtl72eNLHHkGN7NCyoS0nVRMAiQOQl5cX4uLiirVPnDgRX3/9dbH2rl274sCBA8Xa+/Tpgx07dgAAxowZgzVr1ui9Hhoail27dlVR1UREVBvIZDL4OVvDz9kaIzt4QRAEXLqdhciruosyHotJQVpOAQ5euoODl+4A0J1l1szdBk80ssMTnnYI8rSDu9ocMplM4r2hmiZpAPr777+h0WjE5+fPn0ePHj0wePBgg/03b96M/Px88XlKSgpatWpVrH+vXr2watUq8blSyTsXExHVdzKZDE1drdHU1RpjOnlDqxVw8XYmIq+m4ETMXUTFpyIpMw9nb6Tj7I10rD4aCwBwsVEiyNNODEWB7jacWG0EJA1ATk5Oes8/+eQT+Pr6okuXLgb729vb6z3fsGEDLCwsigUgpVIJV1fXqi2WiIjqFLlchgA3GwS42eDlp7whCAJupuXiZFwqTsWn4WRcKi4kZOB2Rh52nkvEznOJAHSn3jdvYCOGoiBPOzjbmEu8N1TVas0coPz8fPz888+YOnVqmYciv//+ewwbNgyWlpZ67fv374ezszPs7OzwzDPP4MMPP4SDg0OJ28nLy0NeXp74PCMjo2I7QUREtZZMJkNDOws0tLNA/9YNAAA5+YU4eyMdUfGpiIpLQ1R8Ku5m5yMqPg1R8WkAYgAADWxV9wORLYI87eHvZs3J1XVcrQlAW7duRVpaGsaMGVOm/idOnMD58+fx/fff67X36tULL7zwAry9vXH16lW899576N27NyIjI6FQGB7SXLBgAebOnVvZXSAiojrGwsxEPGMMgHjq/cm4VETFp+JkXCou3c7EzbRc3EzLxfYztwAA5qZytGpoiyeKDp01soWDFadb1CW15krQoaGhMDMzw++//16m/q+99hoiIyNx9uzZUvtdu3YNvr6+2Lt3L7p3726wj6ERIA8PD14JmoiMWw1cCbouyLxXgDPX08VAdCo+FRn3it9nzcvBQgxEQZ52aOJiDYWck6trUp27EnRcXBz27t2LzZs3l6l/dnY2NmzYgHnz5j22r4+PDxwdHXHlypUSA5BSqeREaSKikmwYAVg6ASpb3Z3hzW3vP7a9/9juwc+iNnM1oKgVf2IqzdrcFE81dsRTjR0BAFqt7vT7okAUFZ+GK0lZiE3JQWxKDjZH3QQAWClN0NrDFk800o0UtfGwg9rCVMpdoYfUim/nqlWr4OzsjL59+5ap/y+//IK8vDy89NJLj+1748YNpKSkwM3NrbJlEhEZlwZBuhGg7CTdUl5Km/vBSP1IcHro8aPBSWWnW09ee+fXyOUyNHaxRmMXawxt1wgAkJaTj1PX03AqLhUn41NxOj4NWXmFOHwlGYevJIvrNna2EkeInvC0hY+jFeQcJZKE5IfAtFotvL29MXz4cHzyySd6r40aNQoNGjTAggUL9No7d+6MBg0aYMOGDXrtWVlZmDt3LgYOHAhXV1dcvXoV77zzDjIzM3Hu3Lkyj/LwZqhERNDdUT41FshNBe6l6X7mpt1/nPZQe5p+e35mJd9YphtBKjbi9JjgpLIFzKyAWnBNH41WwMXEzPuTq3XziWJTcor1U6tM0aaRrRiKWnnYwkpZK8Ym6qQ6dQhs7969iI+Px8svv1zstfj4eMgf+VfAxYsXcfjwYezZs6dYf4VCgbNnz2LNmjVIS0uDu7s7evbsifnz5/MQFxFReclkgL03AO/yracpAO6lPxSKUsvw+P7zwlwAgq7tXpougJWH3OR+eHokLDk2AZ6aApjUzN8Cxf0LLjZzt8FLT3oCAJKz8sTT76PiU3H2RhrScwuw/+Id7L+ou1CjXAY0dbW5f7aZbj6Rp4MFL9RYDSQfAaqNOAJERCSRwjwDo0sPPS4tRGnyS9qqzojfgMYh1Vl9uRRotIhOyEBUXCpOxqchKi4VN9Nyi/VzsDRDm0a6Q2a8nUfpyvP3mwHIAAYgIqI6RhCAghzDh+gOfqYbSRryE9DsOUnLfJzbGfd0gej+KNH5mxnI12j1+jx6O48nGtmiga2Ko0RgAKo0BiAionrkh15AfGSdCECPyivU4PzNDHEe0ck43e08HuVioxTnEbVpZIfmDYzzdh51ag4QERERGaY0USDo/k1bAYi384i6f8gsKj4V/97S3c7jz/OJ+PO8/u08HpxxZgcX3s5DDwMQERFRHfHw7Tyea+UOAMjN1+DsjTScLOF2HisPP7idxxOedgi6f12iADcbo76dBwMQERFRHaYyUyDYxwHBZbydx+8P3c6jZcMHZ5sZ2+08GICIiIjqEZlMBi9HS3g5WmJgUEMA+rfzKLo2Uca9QpyIuYsTMXfFdb0cLB6aXG2Hpq7193YeDEBERET1nKHbeVxLztKNEsXpDp/p3c7jlO52HpZmCrRupDv9vo2nHZ6oR7fzYAAiIiIyMnK5DH7O1vBzfnA7j/ScAkRdT9W7nUd2vgZHrqTgyJUUcV0/ZysE3b8u0RON7ODrVDdv58EARERERFBbmKJbU2d0a+oMQHc7j0u3M8W5RFFxutt5XEnKwpWkLGz85zoAwMbcBG2KzjZrZIfWjerG7Txqf4VERERV4eZJwMwSMLUAzCwAU0vAVHX/sQWgMKsV9xGrLRRyGQLcbBDgVvx2HkWTq8/eSEPGvUIcuHQHBy49uJ1HExdrMRAFedbO23nwQogG8EKIRET1yOpngdhDj+8nU9wPSCpdIBKD0sOPVbrgVKy9hOcPPzZR1ruAVdbbedhbmt2fXK07bNaqmm7nwStBVxIDEBFRPXIlAoj8GsjPAvJzdLfMKMh58FhbUDN1yOQPBSXVg9EovceGgpbqwWiVTQOgYdtaHaSKbudRNEpU0u08/veUN2b2CajS9+aVoImIiIr4ddctJdEU6Aci8XE2UJD7SPv9tkdDVGmPi27SKmjvh7Csyu3PsHWAf9/KbaMaudiYo3cLN/Ru4Qbgwe08Tt0PREW383CylvaaQwxARERk3BSmgEINmKurZ/uawgdhqKyhqSD3fth66LWEM0BOMpB+s3rqrCYP385jXOcHt/NQmUp7rzIGICIiouqkMAEUNoB5JadU/DIG+HdLlZQkpaLbeUjNeG8CQkREREaLI0BERER1ycHPgLx03aTqUhcZANnj+8jK0kdexm3JH7O9h7ZlrgZUtpL9GhmAiIiI6gLT+4eNspOAvz6Utpaq8NRUIOQDyd6eAYiIiKgueGoqoLTWTZAWtAAEQBB0j0tcytqnaHuP6VPith5pN7itR9oU0t5TjAGIiIioLnD0A3ovlLqKeoOToImIiMjoMAARERGR0WEAIiIiIqPDAERERERGhwGIiIiIjA4DEBERERkdBiAiIiIyOgxAREREZHQYgIiIiMjoMAARERGR0WEAIiIiIqPDAERERERGhwGIiIiIjA4DEBERERkdE6kLqI0EQQAAZGRkSFwJERERlVXR3+2iv+OlYQAyIDMzEwDg4eEhcSVERERUXpmZmVCr1aX2kQlliUlGRqvV4tatW7C2toZMJqvSbWdkZMDDwwPXr1+HjY1NlW6byo+fR+3Cz6N24edRu/DzeDxBEJCZmQl3d3fI5aXP8uEIkAFyuRwNGzas1vewsbHhF7gW4edRu/DzqF34edQu/DxK97iRnyKcBE1ERERGhwGIiIiIjA4DUA1TKpX44IMPoFQqpS6FwM+jtuHnUbvw86hd+HlULU6CJiIiIqPDESAiIiIyOgxAREREZHQYgIiIiMjoMAARERGR0WEAqqSvv/4aXl5eMDc3R3BwME6cOFFq/19++QX+/v4wNzdHixYtsHPnTr3XBUHA7Nmz4ebmBpVKhZCQEFy+fLk6d6FeqcrPo6CgAO+++y5atGgBS0tLuLu7Y9SoUbh161Z170a9UtX/jTxs/PjxkMlkWLJkSRVXXX9Vx+cRHR2N5557Dmq1GpaWlmjXrh3i4+Oraxfqlar+PLKysjB58mQ0bNgQKpUKzZo1w/Lly6tzF+ougSpsw4YNgpmZmfDDDz8I//77r/DKK68Itra2wu3btw32P3LkiKBQKIRPP/1UuHDhgvB///d/gqmpqXDu3DmxzyeffCKo1Wph69atwpkzZ4TnnntO8Pb2FnJzc2tqt+qsqv480tLShJCQEGHjxo3Cf//9J0RGRgrt27cXgoKCanK36rTq+G+kyObNm4VWrVoJ7u7uwhdffFHNe1I/VMfnceXKFcHe3l6YPn26EBUVJVy5ckXYtm1bidukB6rj83jllVcEX19fYd++fUJMTIzw7bffCgqFQti2bVtN7VadwQBUCe3btxcmTZokPtdoNIK7u7uwYMECg/2HDBki9O3bV68tODhYeO211wRBEAStViu4uroKn332mfh6WlqaoFQqhfXr11fDHtQvVf15GHLixAkBgBAXF1c1Rddz1fWZ3LhxQ2jQoIFw/vx5wdPTkwGojKrj8xg6dKjw0ksvVU/B9Vx1fB6BgYHCvHnz9Po88cQTwvvvv1+FldcPPARWQfn5+Th58iRCQkLENrlcjpCQEERGRhpcJzIyUq8/AISGhor9Y2JikJiYqNdHrVYjODi4xG2STnV8Hoakp6dDJpPB1ta2Suquz6rrM9FqtRg5ciSmT5+OwMDA6im+HqqOz0Or1WLHjh1o0qQJQkND4ezsjODgYGzdurXa9qO+qK7/Pjp27Ijt27fj5s2bEAQB+/btw6VLl9CzZ8/q2ZE6jAGogpKTk6HRaODi4qLX7uLigsTERIPrJCYmltq/6Gd5tkk61fF5POrevXt49913MXz4cN6IsAyq6zNZuHAhTExM8MYbb1R90fVYdXweSUlJyMrKwieffIJevXphz549GDBgAF544QUcOHCgenaknqiu/z7CwsLQrFkzNGzYEGZmZujVqxe+/vprPP3001W/E3Uc7wZPVAYFBQUYMmQIBEHAsmXLpC7HaJ08eRJffvkloqKiIJPJpC7H6Gm1WgBA//798dZbbwEAWrdujaNHj2L58uXo0qWLlOUZpbCwMBw7dgzbt2+Hp6cnDh48iEmTJsHd3b3Y6JGx4whQBTk6OkKhUOD27dt67bdv34arq6vBdVxdXUvtX/SzPNskner4PIoUhZ+4uDiEh4dz9KeMquMzOXToEJKSktCoUSOYmJjAxMQEcXFxePvtt+Hl5VUt+1FfVMfn4ejoCBMTEzRr1kyvT0BAAM8Ce4zq+Dxyc3Px3nvvYfHixejXrx9atmyJyZMnY+jQoVi0aFH17EgdxgBUQWZmZggKCkJERITYptVqERERgQ4dOhhcp0OHDnr9ASA8PFzs7+3tDVdXV70+GRkZOH78eInbJJ3q+DyAB+Hn8uXL2Lt3LxwcHKpnB+qh6vhMRo4cibNnz+L06dPi4u7ujunTp2P37t3VtzP1QHV8HmZmZmjXrh0uXryo1+fSpUvw9PSs4j2oX6rj8ygoKEBBQQHkcv0/7QqFQhyto4dIPQu7LtuwYYOgVCqF1atXCxcuXBBeffVVwdbWVkhMTBQEQRBGjhwpzJgxQ+x/5MgRwcTERFi0aJEQHR0tfPDBBwZPg7e1tRW2bdsmnD17Vujfvz9Pgy+jqv488vPzheeee05o2LChcPr0aSEhIUFc8vLyJNnHuqY6/ht5FM8CK7vq+Dw2b94smJqaCitWrBAuX74shIWFCQqFQjh06FCN719dUx2fR5cuXYTAwEBh3759wrVr14RVq1YJ5ubmwjfffFPj+1fbMQBVUlhYmNCoUSPBzMxMaN++vXDs2DHxtS5dugijR4/W679p0yahSZMmgpmZmRAYGCjs2LFD73WtVivMmjVLcHFxEZRKpdC9e3fh4sWLNbEr9UJVfh4xMTECAIPLvn37amiP6r6q/m/kUQxA5VMdn8f3338v+Pn5Cebm5kKrVq2ErVu3Vvdu1BtV/XkkJCQIY8aMEdzd3QVzc3OhadOmwueffy5otdqa2J06RSYIgiDlCBQRERFRTeMcICIiIjI6DEBERERkdBiAiIiIyOgwABEREZHRYQAiIiIio8MAREREREaHAYiIiIiMDgMQEVEJZDIZtm7dKnUZRFQNGICIqFYaM2YMZDJZsaVXr15Sl0ZE9YCJ1AUQEZWkV69eWLVqlV6bUqmUqBoiqk84AkREtZZSqYSrq6veYmdnB0B3eGrZsmXo3bs3VCoVfHx88Ouvv+qtf+7cOTzzzDNQqVRwcHDAq6++iqysLL0+P/zwAwIDA6FUKuHm5obJkyfrvZ6cnIwBAwbAwsICjRs3xvbt28XXUlNTMWLECDg5OUGlUqFx48bFAhsR1U4MQERUZ82aNQsDBw7EmTNnMGLECAwbNgzR0dEAgOzsbISGhsLOzg5///03fvnlF+zdu1cv4CxbtgyTJk3Cq6++inPnzmH79u3w8/PTe4+5c+diyJAhOHv2LPr06YMRI0bg7t274vtfuHABf/75J6Kjo7Fs2TI4OjrW3C+AiCpO6ruxEhEZMnr0aEGhUAiWlpZ6y0cffSQIgiAAEMaPH6+3TnBwsDBhwgRBEARhxYoVgp2dnZCVlSW+vmPHDkEulwuJiYmCIAiCu7u78P7775dYAwDh//7v/8TnWVlZAgDhzz//FARBEPr16yeMHTu2anaYiGoU5wARUa3VrVs3LFu2TK/N3t5efNyhQwe91zp06IDTp08DAKKjo9GqVStYWlqKr3fq1AlarRYXL16ETCbDrVu30L1791JraNmypfjY0tISNjY2SEpKAgBMmDABAwcORFRUFHr27Innn38eHTt2rNC+ElHNYgAiolrL0tKy2CGpqqJSqcrUz9TUVO+5TCaDVqsFAPTu3RtxcXHYuXMnwsPD0b17d0yaNAmLFi2q8nqJqGpxDhAR1VnHjh0r9jwgIAAAEBAQgDNnziA7O1t8/ciRI5DL5WjatCmsra3h5eWFiIiIStXg5OSE0aNH4+eff8aSJUuwYsWKSm2PiGoGR4CIqNbKy8tDYmKiXpuJiYk40fiXX35B27Zt8dRTT2Ht2rU4ceIEvv/+ewDAiBEj8MEHH2D06NGYM2cO7ty5g9dffx0jR46Ei4sLAGDOnDkYP348nJ2d0bt3b2RmZuLIkSN4/fXXy1Tf7NmzERQUhMDAQOTl5eGPP/4QAxgR1W4MQERUa+3atQtubm56bU2bNsV///0HQHeG1oYNGzBx4kS4ublh/fr1aNasGQDAwsICu3fvxptvvol27drBwsICAwcOxOLFi8VtjR49Gvfu3cMXX3yBadOmwdHREYMGDSpzfWZmZpg5cyZiY2OhUqnQuXNnbNiwoQr2nIiqm0wQBEHqIoiIyksmk2HLli14/vnnpS6FiOogzgEiIiIio8MAREREREaHc4CIqE7i0XsiqgyOABEREZHRYQAiIiIio8MAREREREaHAYiIiIiMDgMQERERGR0GICIiIjI6DEBERERkdBiAiIiIyOgwABEREZHR+X8mUNwmr71sYwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame(trainer.state.log_history)\n",
    "df.to_csv(\"./icebreaker/log_history.csv\")\n",
    "\n",
    "training_loss_data = []\n",
    "eval_loss_data = []\n",
    "for i in range(len(df)):\n",
    "    row = df.iloc[i]\n",
    "    epoch, train_loss, eval_loss = row[\"epoch\"], row[\"loss\"], row[\"eval_loss\"]\n",
    "\n",
    "    if not np.isnan(eval_loss):\n",
    "        eval_loss_data.append((epoch, eval_loss))\n",
    "\n",
    "    if not np.isnan(train_loss):\n",
    "        training_loss_data.append((epoch, train_loss))\n",
    "\n",
    "# Extract x and y values for training and evaluation losses\n",
    "training_epochs, training_losses = zip(*training_loss_data)\n",
    "eval_epochs, eval_losses = zip(*eval_loss_data)\n",
    "\n",
    "# Create a figure and axis\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot the training loss\n",
    "ax.plot(training_epochs, training_losses, label='Training Loss')\n",
    "\n",
    "# Plot the evaluation loss\n",
    "ax.plot(eval_epochs, eval_losses, label='Evaluation Loss')\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.set_title('Training and Evaluation Loss')\n",
    "\n",
    "# Add a legend\n",
    "ax.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
