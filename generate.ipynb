{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(32000, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./new_tokenizer/\")\n",
    "model_path = \"icebreaker/checkpoint-900\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model size:  110418432\n"
     ]
    }
   ],
   "source": [
    "# model size\n",
    "print(\"model size: \", model.num_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Fréttir> Það kviknaði í laugardalshöllini í gærmorgun. Þetta er á meðal þeirra sem eru að koma frá því í gær.„Það var ekki alveg sama,“ segir Guðmundur og bætir við að það verði ekki hægt að segja af hverju. „Þetta er mjög mikilvægt fyrir okkur en þegar ég veit að vera með þetta. Ég held að ég sé alltaf í þessu,\" segir hann.Hann segir að hún hafi verið að finna til þess að gera neitt.„Ég myndi hafa tekið mig upp, ef maður vill að gera þá sem hefur gert eitthvað.“Í samtali við Fréttablaðið að málið geti haft áhrif á að ofan í sumar.<Íþróttir> <Fótbolti - Ísland> Knattspyrnuliðið hefur ákveðið að vinna aftur á næstu viku en liðið vann leikinn gegn Barcelona í kvöld. Lokatölur urðu 1-1 sigur á útivelli í nótt. Liðið hafði hins vegar betur eftir að skora sjö mörk og staðan 2-0 sigri liðanna í kvöld.Ísland kom næstur í undanúrslit liðsins í dag en þeir skoruðu tvö stig fyrir leikslok.Leikur Íslands var með 18 stiga forskoti\n"
     ]
    }
   ],
   "source": [
    "from transformers import TextGenerationPipeline\n",
    "\n",
    "# Create a text generation pipeline\n",
    "pipeline = TextGenerationPipeline(model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Generate text\n",
    "# generated_text = pipeline(\"\", max_length=512, num_return_sequences=1, repetition_penalty=1.2, top_k=50, top_p=0.95, temperature=1.1)\n",
    "generated_text = pipeline(\n",
    "    \"<Fréttir> Það kviknaði í laugardalshöllini í gærmorgun\",\n",
    "    max_length=206,\n",
    "    num_return_sequences=1,\n",
    "    repetition_penalty=1.2,\n",
    "    top_k=50,\n",
    "    top_p=0.5,\n",
    "    do_sample=True,\n",
    "    temperature=0.9,\n",
    ")\n",
    "\n",
    "# Print the generated text\n",
    "print(generated_text[0][\"generated_text\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
